<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6" crossorigin="anonymous"/><link href="https://use.fontawesome.com/releases/v5.15.1/css/all.css" rel="stylesheet"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700&amp;display=swap" data-optimized-fonts="true"/><meta name="next-head-count" content="5"/><link rel="preload" href="/_next/static/css/5d6e18f3c7418c4edd0e.css" as="style"/><link rel="stylesheet" href="/_next/static/css/5d6e18f3c7418c4edd0e.css" data-n-g=""/><link rel="preload" href="/_next/static/css/00fb12490a470845edbc.css" as="style"/><link rel="stylesheet" href="/_next/static/css/00fb12490a470845edbc.css" data-n-p=""/><noscript data-n-css=""></noscript><link rel="preload" href="/_next/static/chunks/webpack-50207a9308fa24ceece0.js" as="script"/><link rel="preload" href="/_next/static/chunks/framework-106d25c2ed81dc45938c.js" as="script"/><link rel="preload" href="/_next/static/chunks/main-1edd7ef5819b2a11bbed.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/_app-067f3f505bf9f3e67d67.js" as="script"/><link rel="preload" href="/_next/static/chunks/9282-be3425a58587a45a3808.js" as="script"/><link rel="preload" href="/_next/static/chunks/7507-81af9623502386b8c24a.js" as="script"/><link rel="preload" href="/_next/static/chunks/5835-a34425b363ee7a543e5a.js" as="script"/><link rel="preload" href="/_next/static/chunks/7467-8b8ea4cfd89ac7664267.js" as="script"/><link rel="preload" href="/_next/static/chunks/9238-a3fd48a971513fe11c50.js" as="script"/><link rel="preload" href="/_next/static/chunks/8075-48adf4f568d38ee91732.js" as="script"/><link rel="preload" href="/_next/static/chunks/2852-de21a24c1010e6297a46.js" as="script"/><link rel="preload" href="/_next/static/chunks/8151-b7f0693b6af81db553cf.js" as="script"/><link rel="preload" href="/_next/static/chunks/115-1251df7fc586bb041c3f.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/altwalk-7cbb331762e92c9aadad.js" as="script"/><style data-href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700&display=swap">@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmSU5fBBc-.woff) format('woff')}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOmCnqEu92Fr1Mu4mxM.woff) format('woff')}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmEU9fBBc-.woff) format('woff')}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmWUlfBBc-.woff) format('woff')}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmSU5fCRc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmSU5fABc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmSU5fCBc4AMP6lbBP.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmSU5fBxc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmSU5fCxc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmSU5fChc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:300;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmSU5fBBc4AMP6lQ.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOmCnqEu92Fr1Mu72xKKTU1Kvnz.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOmCnqEu92Fr1Mu5mxKKTU1Kvnz.woff2) format('woff2');unicode-range:U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOmCnqEu92Fr1Mu7mxKKTU1Kvnz.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOmCnqEu92Fr1Mu4WxKKTU1Kvnz.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOmCnqEu92Fr1Mu7WxKKTU1Kvnz.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOmCnqEu92Fr1Mu7GxKKTU1Kvnz.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOmCnqEu92Fr1Mu4mxKKTU1Kg.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmEU9fCRc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmEU9fABc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmEU9fCBc4AMP6lbBP.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmEU9fBxc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmEU9fCxc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmEU9fChc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmEU9fBBc4AMP6lQ.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmWUlfCRc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmWUlfABc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmWUlfCBc4AMP6lbBP.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmWUlfBxc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmWUlfCxc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmWUlfChc4AMP6lbBP.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v27/KFOlCnqEu92Fr1MmWUlfBBc4AMP6lQ.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style></head><body><div id="__next"><style data-emotion="css-global 17xi5l2">html,body{padding:3rem 1rem;margin:0;min-height:100%;background-color:#ffffff;color:#363636;font-family:sans-serif;font-size:1rem;}a{color:#363636;-webkit-text-decoration:none;text-decoration:none;}code{color:#363636;}text{color:#363636;}section{padding:1rem;}h1{color:#363636;}h2{color:#363636;}h3{color:#363636;}h4{color:#363636;}h5{color:#363636;}h6{color:#363636;}p{color:#363636;}li{color:#363636;}td{color:#363636;}th{color:#363636;}</style><div><div class="container"><div class="row border fixed-top"><div class="container-fluid"><div class="row"></div><nav class="navbar navbar-expand-lg navbar-light bg-light" collapseonselect="true" expand="lg"><div class="row"><button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNavDropdown" aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavDropdown"><a class="navbar-brand" href="./">SSZ - SimpleSerialize</a><ul class="navbar-nav me-auto mb-2 mb-lg-0"><li class="nav-item"><a class="nav-link" href="/">Home</a></li><li class="nav-item"><a class="nav-link" href="/show">Specifications</a></li><li class="nav-item"><a class="nav-link" href="/simulator">Visualizer </a></li><li class="nav-item"><a class="nav-link" href="/Converter">SSZ for Eth2.0</a></li><li class="nav-item"><a class="nav-link" href="/walk">Overview</a></li><li class="nav-item"><a class="nav-link" href="/active">Implementations</a></li><li class="nav-item"><a class="nav-link" href="./ssztesting">Testing</a></li><li><a class="nav-link" href="https://github.com/scottypoi/ssz-simpleserialize">GitHub</a></li></ul></div></div></nav></div></div><div class="row" style="z-index:0"><div class="container position-relative"><div class="row"><div class="col-2 position-absolute start-0 overflowy-auto"><div class="container"><div class="row"><h5 class="border-primary border border-bottom-0">d<!-- -->e<!-- -->s<!-- -->i<!-- -->g<!-- -->n</h5></div><div class="row"><ul class="nav nav-tabs flex-column p-3"><li class="nav-item"><a class="nav-link active">general</a></li></ul></div></div><div class="container"><div class="row"><h5 class="border-primary border border-bottom-0">t<!-- -->y<!-- -->p<!-- -->e<!-- -->s</h5></div><div class="row"><ul class="nav nav-tabs flex-column p-3"><li class="nav-item"><a class="nav-link active">types</a></li><li class="nav-item"><a class="nav-link active">basic</a></li><li class="nav-item"><a class="nav-link active">bitfields</a></li><li class="nav-item"><a class="nav-link active">complex</a></li><li class="nav-item"><a class="nav-link active">union</a></li></ul></div></div><div class="container"><div class="row"><h5 class="border-primary border border-bottom-0">r<!-- -->e<!-- -->p<!-- -->r<!-- -->e<!-- -->s<!-- -->e<!-- -->n<!-- -->t<!-- -->a<!-- -->t<!-- -->i<!-- -->o<!-- -->n</h5></div><div class="row"><ul class="nav nav-tabs flex-column p-3"><li class="nav-item"><a class="nav-link active">fixed_variable_size</a></li><li class="nav-item"><a class="nav-link active">sequences</a></li></ul></div></div><div class="container"><div class="row"><h5 class="border-primary border border-bottom-0">p<!-- -->a<!-- -->r<!-- -->t<!-- -->i<!-- -->a<!-- -->l<!-- -->s</h5></div><div class="row"><ul class="nav nav-tabs flex-column p-3"><li class="nav-item"><a class="nav-link active">partials</a></li></ul></div></div><div class="container"><div class="row"><h5 class="border-primary border border-bottom-0">m<!-- -->e<!-- -->r<!-- -->k<!-- -->l<!-- -->e<!-- -->i<!-- -->z<!-- -->a<!-- -->t<!-- -->i<!-- -->o<!-- -->n</h5></div><div class="row"><ul class="nav nav-tabs flex-column p-3"><li class="nav-item"><a class="nav-link active">chunkify</a></li><li class="nav-item"><a class="nav-link active">hashing</a></li><li class="nav-item"><a class="nav-link active">merkle_proofs</a></li><li class="nav-item"><a class="nav-link active">mixin</a></li><li class="nav-item"><a class="nav-link active">subtree_merkleization</a></li><li class="nav-item"><a class="nav-link active">proof_backings/classic</a></li></ul></div></div><div class="container"><div class="row"><h5 class="border-primary border border-bottom-0">n<!-- -->a<!-- -->v<!-- -->i<!-- -->g<!-- -->a<!-- -->t<!-- -->i<!-- -->o<!-- -->n</h5></div><div class="row"><ul class="nav nav-tabs flex-column p-3"><li class="nav-item"><a class="nav-link active">generalized_indices</a></li><li class="nav-item"><a class="nav-link active">paths</a></li><li class="nav-item"><a class="nav-link active">summaries_expansions</a></li></ul></div></div></div><div class="col-9 position-absolute end-0 overflowy-auto"></div></div></div></div><script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js" integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf" crossorigin="anonymous"></script></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"markdowns":[{"data":"# Eth 2.0 - Simple Serialize\n\nSimple Serialize (SSZ) is a standard for the encoding and merkleization of structured data, designed for ETH 2.0.\n \n\nThis document outlines general things such as the principles and design choices behind SSZ.\nIt does not spec any SSZ behavior, and can be ignored as an implementer of SSZ,\nbut may provide valuable insight into the bigger picture of SSZ.\n\n## Principles of SSZ\n \nTo describe design choices in SSZ as a short list of properties,\nloosely based on the desires outlined in the [SSZ specs Readme](../README.md):\n\n- Simple\n- Bijective\n- Compact\n- Merkle-first\n- Efficient to traverse\n\nThese properties are based on experience with Eth1 smart contracts, blockchain protocol engineering in general,\nand feedback from lots of different implementers and stake-holders in Eth2.\n\nOther properties such as Security, readability and common encoding features are desired as well,\nbut do not make SSZ principally different from other encodings.\n\nThe main use-case of SSZ is to provide a consistent encoding and merkleization framework for the core of the Eth2 protocol.\nHowever, use outside of the core protocol, such as in smart contracts or layer-2 solutions, is also considered and factored into the design.\n\n### Simple\n\nSSZ is meant to map well to common raw datatypes, and avoid twiddling with bits or nibbles in serialization.\n\n- It has common basic data types\n- It has fixed-length types to avoid unnecessary lengths/offsets\n- Types to describe the structure\n\nAnd compared to RLP, an encoding previously used in Ethereum:\nRLP had some simplicity, but lacks in typing and merkleization features, making it more difficult to use than desired.\n\n### Bijective\n\nThis property expands to two conditions:\n\n- No two different representations can exist for the same value of a single type.\n- No two different values of the same type can be have the same representation.\n\nThis applies to both merkleization and serialization.\n\nHowever, this is not maintained between different types:\n\n- Different types may still have overlapping representations in merkleization or serialization.\n  - Serialization example: `Vector[uint16, 4]`, `Vector[uint32, 2]`, `Vector[uint64, 1]`, `uint64` are all fixed-length and 8 bytes.\n    Another more verbose example: a fixed-length container with different fixed-length fields, but the same total size.\n  - Merkleization example: A `Container` with a `Vector[uint32, 8]` and `uint64` field has the same merkleization structure as a `List[uint64, 4]`.\n    Or focusing on the hash-tree-root only: a `Vector[byte, 32]` can have any hash-tree-root value.\n- Expansions, summaries and partials can be thought of as different types because of their differences in completeness,\n  so they may also break bijective. By definition, they break hash-tree-root the beijective property.\n\n### Compact\n\nSSZ achieves aims for compactness in both serialization, as merkle-proofs.\n\nIn general in the serialization or merkleization, no information that can be determined from the type already is embedded.\nE.g. the names of container fields are not part of the serialized data, unlike a format such as JSON.\nThis means that the reader of the data has to know the type, but this is almost a given, since input data is untrusted,\nand validated and parsed using a pre-determined type before further processing.\n\nFor serialization of fixed-length types, the elements are packed together, and do not result in any extra bytes when used as elements in dynamic types such as lists.\nA good example of this is the validator registry in the Eth2 `BeaconState`: hundreds of thousands of unique validators can be packed into a big list, with 0 overhead.\n\nFor serialization of dynamic types, it is more of a trade-off with traversal speed, but 4-byte offsets were adopted as a way to enable fast random access of list elements,\nwhile keeping the size relatively low. Offsets are only used for dynamic-length element types, whose contents are often significantly bigger than 4 bytes.\n\nFor merkleization, a binary tree backs every merkle structure. Since the branching factor is lower than the previously used Merkle Patricia Tree, less nodes are required to reach into a leaf of a merkle tree.\nAnd on the application level, an arbitrary key-value store is avoided, since a `List` can be packed together better, and have a smaller key depth,\nthus more efficiency in multi-proofs and avoiding the cost of unbalanced tree shapes.\n\n### Merkle-first\n\nThe intention of having a custom type system is also to give anything that can be interpreted by the protocol a sound single generalized merkle-root.\n\nAnd not just a merkle-root, but also features that make proofs small, avoid complexity in merkleization,\nand make it as flexible as possible to build and interpret proofs for a data-structure.\n\nThis merkle-first also enables advanced features such as [summaries and expansions](./navigation/summaries_expansions.md),\n[partials](./partials/partials.md), [generalized indices](./navigation/generalized_indices.md) and [multi-proofs](./merkleization/merkle_proofs.md).\n\n### Efficient to traverse\n\nEfficient traversal is a feature that was later introduced into SSZ with the creation\nof [Simple Offset Serialization (SOS)](https://gist.github.com/karalabe/3a25832b1413ee98daad9f0c47be3632).\nThis guarantees a `O(log(N))` lookup speed for deeply nested structures. And offsets even enable `O(1)` random access in lists of dynamic-length elements.\n\nThe trade-off here is the use of offsets, which are based on the sizes of subsets of the structure, making streaming of dynamic-length SSZ data impossible.\n\nHowever, since SSZ also has fixed-length types, and is very efficient about typing data structures,\noften the size of a data structure can be computed much faster than actually serializing it.\n\nThe primary part of the `BeaconState`, the validator registry, is a good example of this again.\nThe size is computed with `length * fixed_element_size`, instead of writing every single element.\nAnd access to any validator by index is only a bit of pointer math.\n\nBy doing the size computation separately, some kind of streaming where the size is given, or computed pre-computed before encoding, is possible.\nReducing the intermediate memory requirements in components such as the Eth2 networking request-response code.\n\nThe merkle tree is also efficient for lookups, compared to other trees, even though it is a binary tree:\n[generalized indices](./navigation/generalized_indices.md) can statically describe the tree node location of any element path.\nThis allows any merkle-node lookup to be optimized to a `O(log(N))` operation,\nwhere `N` is the abstract data size (SSZ does not force a uniform data-structure),\nand where `log(N)` matches the length of the generalized index.\nAnd the purely static parts of the path can even be computed at compile time,\nto improve lookup speeds without writing specialized verbose manual lookup routines.\n","topic":"general"},{"data":"\n\n# Types\n\nTypes define how we interpret and interact with SSZ data.\nIn addition to this they provide readability, and guard users from mixing up data or processing input beyond intended limits.\n\n## Readability\n\nTypes can be aliased to more specific types, good use of type aliasing can make a data-structure much clearer.\nE.g. `BLSSignature` instead of `Vector[byte, 96]`.\n\n## Default values\n\nPart of the promise of types is that data structures have defaults, avoiding `null` (a.k.a. \"the billion dollar mistake\").\nDefault values are recursive; elements in composite types such as containers are initialized with their respective default initializations.\n\n## Merkle proofs \n\nEvery type deterministically describes the shape of the Merkle tree representing the type:\n reasoning about the shape of a proof is abstracted away by the typing layer.\nMost types do so statically: the shape can be constructed on compile time, and navigation is stable (See [generalized indices](../navigation/generalized_indices.md)).\nSome types (e.g. those based on Sparse Merkle Trees) are not static, but are deterministic based the contents of the proof.\n\nMapping a *valid (to the type)* merkle tree to that same type is bijective:\n- No two different values *of the same type* can merkleize to the same root\n- No two roots can be derived for the same value *of the type used for the root*.\n\nDo note that some different types may merkleize to the same root:\n - Intentionally: see [summaries and expansions](../navigation/summaries_expansions.md).\n - Or because of different types with the same structure:\n   Two values *of different types* can merkleize to the same root, e.g. a `uint256(123)` and `uint8(123)` have the same root.\n   Or more exceptionally, a `Container` with 4 `Bytes32` fields can have the same root as a `Vector[uint64, 16]`.\n   Hence, typing is essential to consuming a proof for data, and should not be chosen arbitrarily by another actor (if a different type has any meaning to the application of the proof).\n\n## Representation\n\nMapping *valid* instances of the same type to a byte sequence is bijective:\n- Serialization: Any two different values *of the same type* cannot have the same representation.\n- Deserialization: Any *valid* representation *of a given type* cannot be interpreted as two different values *of that same type*.\n\nMapping *any* instance of a type to any byte sequence is *injective and non-surjective*:\n- Serialization: All type instantiations can be serialized to a unique (to the type) value.\n- Deserialization: not all byte sequences are a valid representation for a given type, because of constraints such as:\n   - representation length (See [fixed length](../representation/fixed_variable_size.md))\n   - element count (See [list limits](./complex.md#list-limits))\n   - [element offsets](../representation/sequences.md#offsets)\n   - delimiters (See [bitlists](./bitfields.md#bitlist))\n   - selectors (See [union](./union.md))\n   - more, this is not an exhaustive list.\n","topic":"types"},{"data":"\n# Basic types\n\nThe basic types all strictly follow the basic-type principles:\n- 1 to 32 bytes long, for merkleization purposes.\n- A power of 2 bytes long, for packing/alignment purposes. See [chunkification](../merkleization/chunkify.md).\n- [Fixed length](../representation/fixed_variable_size.md)\n\n## Unsinged integers\n\nType: `uintN`, where `N` can be: `8, 16, 32, 64, 128, 256`.\n\nAlias: `uint8 \u003c-\u003e byte`\n\nDefault value: `0`\n\nA `N`-bit unsigned integer. \n\n### Representation\n\nThe integers have a little-endian representation, and represented in their respective byte sizes.\n\n### Merkleization\n\nThe integers, represented as bytes, are padded on the right side with zeroed bytes to a total of 32 bytes for merkleization.\nNote:\n - Some complex types pack smaller integers together into 32 bytes, to reduce the merkleization cost.\n - Because of the little-endianness and right-padding, equal integers of different bit-sizes all map to the same 32 bytes value.\n\n### Size\n\n`size_of(uintN): N / 8`\n\n\n## Booleans\n\nType: `boolean`\n\nAlias: `bit`\n\nDefault value: `False` \n\n### Representation\n\nA single byte: 1 (i.e. `0b00000001`) for `True`, and 0 (i.e. `0b00000000`) for `False`.\n\nTo have a one-to-one correspondence from value to serialized byte, the non-utilized bits of the byte MUST all be zero bits.\n\n### Merkleization\n\nThe boolean represented as byte is merkleized exactly like `byte`, including the ability to pack (but only to `byte` precision, refer to bitfields for more efficient packing).\n\n### Size\n\n`size_of(bool): 1`\n","topic":"basic"},{"data":"\n\n# Bitfields\n\nBitfields are collections of booleans, backed by sequences of bytes: a bit at sequence index `i` is put into byte `i // 8` and matches `1 \u003c\u003c (i % 8)` within that byte.\n\n## Bitfields vs Collections\n\nBitfields represent boolean data in a packed form, as opposed to lists or vectors of booleans that do not efficiently utilize space.\n\nE.g. the representation of a `Bitvector[N]` is 8 times smaller than a `Vector[boolean, N]`.\nAnd because of [chunkification](../merkleization/chunkify.md) adapting to bitfields better than boolean collections, the Merkle tree is also 8 times smaller.  \n\n\n## Bitvector\n\nType: `Bitvector[N]`\n\nDefault value: `N` bits, all set to `0` \n\nNote that a `Bitvector[0]` is an illegal type, since fixed-length types many not have 0 byte-length representations.\n\n### Representation\n\nA fixed-length sequence of `N` bits, packed into `(N + 7) // 8` bytes.\n\nIf `N` is not a multiple of 8, the remainder of bits (high end of byte) in the *last* byte in the sequence MUST be zeroed.\n\n### Merkleization\n\n`root = merkle_subtree(chunkify(bitvector_value))`,\n see [`merkle_subtree`](../merkleization/subtree_merkleization.md), [`chunkify`](../merkleization/chunkify.md).\n\nNote: A bitvector is merkleized the same as serializing it, and then merkleizing it as a `Vector[byte, ((N + 7) // 8)]`.\n\n\n## Bitlist\n\nType: `Bitlist[N]`\n\nDefault value: `0` bits, i.e. an empty bitlist.\n\nA dynamic-length sequence, with a limit of `N` bits, packed into bytes.\nThe limit here reflects the limit behavior as described by `List`: it enforces input constraints, and stabilizes merkleization depth. \n\n### Representation\n\nFrom the offset coding the length (in bytes) of the bitlist is known; the bitlist cannot have redundant zero bytes.\nAn additional `1` bit is appended so that the length in bits will also be known: \"the delimiting bit\".\n\nThis delimiting `1` bit is put in what would effectively be the bitfield index `bit_length(bitlist_value)`.\nNote that for an empty bitlist that would be the first bit at index 0: A single zeroed byte, or empty bytes, is illegal as bitlist representation. \n\nBecause of this delimiting bit, the total byte length for serialization purposes is: `(((N + 1) + 7) // 8) == ((N // 8) + 1)`\n\n### Merkleization\n\nFor merkleization, the length of the bitlist is mixed in with the root, and hence the delimiting bit is not used for merkleization.\nSimilarly to a `List`, the subtree is padded to fit the limit of the bitlist.\n\n`root = mix_in_num(merkle_subtree(chunkify(bitlist_value), limit=chunk_count(Bitlist[N])), bit_length(bitlist_value))`,\n see [`merkle_subtree`](../merkleization/subtree_merkleization.md),\n  [`chunkify, chunk_count`](../merkleization/chunkify.md) and [`mix_in_num`](../merkleization/mixin.md). \n\n","topic":"bitfields"},{"data":"\n\n# Complex types\n\nComplex types are types that can hold multiple values at the same time, with usage similar to that of a `struct` in popular programming languages.\n\nThe complex types are all serialized like [Sequences](../representation/sequences.md).\n\nA complex object is considered fixed size if all of the contained elements are fixed size, and type has a fixed element count (e.g. Lists cannot be fixed size).\n\nElements can be read and written in `O(1)`, as they are indexed (using an [offsets prologue](../representation/sequences.md#offsets) if `T` is variable size).\n\n## Vector\n\nType: `Vector[T, N]`\n\nDefault value: `[default(T)] * N`, i.e. all elements set to their default value.\n\nA Vector is a sequence of elements, all of the same type `T`, and of fixed length `N`.\n\nEmpty vectors (`N = 0`) are illegal types, even if the element type `T` is dynamic length.\nThis is to avoid fixed-length types of 0 length, which break various size assumptions in deserialization. \n\n### Representation \n\nSerialized and deserialized like a [Sequence](../representation/sequences.md) of the `values`, all of type `T`.\n\n### Merkleization\n\n`root = merkle_subtree(chunkify(values))`, see [`merkle_subtree`](../merkleization/subtree_merkleization.md) and [`chunkify`](../merkleization/chunkify.md)\n\n\n## Lists\n\nType: `List[T, N]`\n\nDefault value: `[]`, i.e. empty list.\n\nA List is a sequence of elements, all of the same type `T`, and can be any length from `0` to `N` (inclusive).\n\nUnlike `Vector` and `Container`, a list can have a `N = 0` limit, since it is dynamic length regardless, \nand types containing the list can handle a 0 byte length representation of a dynamic length element.\n\n### List Limits\n\nThe maximum list length is preset as `N` and called the \"list limit\".\n\nThis limit is preset for two primary reasons:\n- Stable merkleization: there are no variable numbers in the hash-tree-root definition.\n- Strong guarantees on inputs: lists should never contain more elements than their limit states it was designed for.\n\n#### Allocation\n\nFor small list limits, the limit type information may help to optimize for a single allocation of full list capacity.\nHowever, list limits can be arbitrarily high as the cost for serialization and merkleization is `O(n)`:\n - the limit is not padded to in serialization\n - `O(log(N))` [zero-hashes](../merkleization/hashing.md#zero-hashes) may need to be merged during merkleization.\nHence, lists should not be allocated to their full limit for larger numbers.\n\n### Representation\n\nSerialized and deserialized like a [Sequence](../representation/sequences.md) of the `values`, all of type `T`.\nThe limit of the list should be enforced, to ensure that no more than `N` elements are serialized or deserialized.\n\nNote: A list is by definition variable-size, but this does not necessarily mean its elements are.\n\n### Merkleization\n\nNote: the contents subtree (not including the length mix-in) is padded to fit the limit of the bitlist.\n\n`root = mix_in_num(merkle_subtree(chunkify(values), limit=chunk_count(List[T, N])), length)`,\n see [`merkle_subtree`](../merkleization/subtree_merkleization.md),\n  [`chunkify, chunk_count`](../merkleization/chunkify.md) and [`mix_in_num`](../merkleization/mixin.md). \n\n\n## Container\n\nType: `Container[(\u003cK_i\u003e: \u003cT_i\u003e)+]`\n\nDefault value: `Container[(\u003cK_i\u003e: \u003cT_i\u003e)+](default(T_i)...)`, i.e. all fields set to their default value.\n\nA Container is a predefined sequence of fields, each field can be defined as any type `T_i` independently from the other fields, and is identified by a unique (relative to the other fields) name `K_i`.\n\nNote that field names are not included in serialization or merkleization: a Container is not self-describing.\n\nAn empty container, i.e. 0 fields, is an illegal type. Fixed-length types cannot have a 0 length serialized representation.\n\n### Representation\n\nSerialized and deserialized like a [Sequence](../representation/sequences.md) of the `fields`, each of their own type `T_i`.\n\n### Merkleization\n\n`root = merkle_subtree(chunkify(fields))`,\n see [`merkle_subtree`](../merkleization/subtree_merkleization.md), [`chunkify`](../merkleization/chunkify.md).\n\n","topic":"complex"},{"data":"\n\n# Union\n\nType: `Union[type_0, type_1, ...]`\n\nDefault: `default(type_0)`\n\nA [`Union`](https://en.wikipedia.org/wiki/Union_type) provides the ability to represent a set of predetermined types in the same tree and serialization position.\n\nA special `null` type may be used as first type parameter to emulate an `Option`, any other type parameter than the first MUST not be `null`.\nA `null` as a standalone type is illegal.\n\nAn Union is considered to have a dynamic encoding-size, even if all the selectable options have the same type or happen to have the same serialized byte length.\n\n## Representation \n\nSerialization is defined as an `uint32` for the type index, followed by the serialization of the selected option.\n\n`null` is represented as an empty byte sequence (i.e. remaining scope after the type_index is 0).\n\n## Merkleization\n\nMerkleization is defined as `mix_in_num(x, i)` where `x` is the root of the selected option with index `i` (right-padded to 32 bytes, effectively an `uint256`).\n","topic":"union"},{"data":"\n\n\n# Fixed-size and variable-size\n\nSSZ makes a difference between fixed-size and dynamic-size objects, based on a recursive definition to check if the byte-length is variable or not.\n\nAn object is considered **fixed-size** if it is:\n- a basic-type\n- a fixed composition of fixed-size types\n\nThis fixed-size property breaks when e.g. there is a variable amount of elements,\n or the exact type of its serialization cannot be determined without reading data.\n \nAn object is considered **variable-size** if and only if it is not fixed-size.\n","topic":"fixed_variable_size"},{"data":"\n\n# Representation of sequences\n\nRepresentation of sequences can be thought of as two parts: the fixed-size part, and the variable-size part.\n\nFixed-size types do not have a variable part.\n\nNote that if all elements have the same type, the two parts can be specialized. However, conceptually it is all the same.\n\n## Fixed part\n\nFor each of the elements in order, if the element type is: \n\n- fixed-size:\n  - Serialize the element and append it to the fixed-size part.\n    - Lists of fixed-size elements effectively concatenate all elements,\n      the naming of the fixed-size part as whole does not apply to the list, but to element-type.\n- variable-size:\n  - Append an offset to the fixed-size part, pointing to the start of the element data in the variable-size part.\n  - Serialize the element and append it to the variable size part.\n\n### Offsets\n\nWithin the fixed-size part offsets may be encoded to locate elements in the variable-size part.\n\nOffsets are 4 bytes each, typed as `uint32`, and can range from `[bytelen(fixed_part), bytelen(fixed_part) + bytelen(variable_part)]`. I.e. the fixed-part byte length is included as part of the offset.\n\nEach offset is pointing to the start of the serialized data, the index of the first byte of the element.\n\nFor each offset, it MUST hold that `offsets[i-1] \u003c= offsets[i] \u003c= offsets[i+1]`, so that elements can be read from the byte stream following the offsets in order.\n\nIt also MUST hold that the first offset aligns correctly:\n\n- In a List this means that the first offset MUST be an exact multiple of the offset size, i.e. a multiple of 4.\n- In a Container, this means that the first offset equals the fixed-size part of the container.\n  - Technically these first 4 offset bytes are unnecessary encoding, but they provide consistency between field types,\n    to reduce complexity and increase the ability to generalize this in implementations.\n\nSome elements in the variable-size part may be empty, this can result in:\n\n- sequential equal offsets\n- the last offset being equal to the end of the scope.\n\nThere may be a dynamic number of variable-size elements all of the same type,\nin this case the element count can be derived from the _first offset_: `offset / 4`, as each offset matches an element and is 4 bytes.\n\n## Variable part\n\nFor variable-size elements, the elements are serialized, tightly packed, appended in order to the variable-size part.\n","topic":"sequences"},{"data":"\n\n# Partials\n\nOne of the main uses of multi-proofs are interactions with verifiable pre-states: a merkle multi-proof verifies the data, and the data is used in a computation.\n\nWith SSZ, this data can be (partially) typed, and interacted with, without dealing with the underling merkleization.\n\nThis separation of the typed interface and the multi-proof enables different abstractions and use-cases:\n- The multi-proof is abstracted away, merkleization and lookups may be implemented by specialized proof-backings.\n- The verification, lookups and modifications are all just an interface feature;\n   environments can decide on when and how to implement this.\n   - E.g. an aggregate proof can be verified first, and subsequent individual processes can be given a scoped interface to interact with the proof data.\n- The typing interface can be extended, and new proof-backings may be introduced in the future.\n\nNote that the concept of [Summaries and expansions](../navigation/summaries_expansions.md) is a subset of that of partials:\ninstead of summarizing a type nicely at the edges of the type (i.e. summarizing fields or elements),\narbitrary subsets of an element can be summarised as a whole.\n\nDeciding between a partial and a summary is not difficult:\n- If you need a small subset, or a very arbitrary subset, utilize the expressive flexibility of a partial.\n- If you only need to leave out a single part, leave it out by summarizing it, and keep the type as static as possible.\n\n## Core functionality \n\n### `PartialType(base_type: SSZType, paths: Set[Path])`\n\nThe idiomatic syntax here differs strongly per implementation, as meta-programming is not a first-class citizen in every language.\nThe core idea however, is to take an existing type, define the subset (e.g. a list of [ssz paths](../navigation/paths.md)) of information you need,\n and construct a type structure to interact with multi-proofs. \n\n### `interface(partial_type: PartialType, proof_backing: ProofBacking) -\u003e Partial`\n\nGiven a partial type structure, a proof-backing can be wrapped and create a partial.\n\n### `scope(partial_type: PartialType, paths: Set[Path]) -\u003e PartialType`\n\nSince not every `base_type` can be provided in the same level of detail to create a partial-type\n (e.g. only select a specific set of indices of a list), additional changes to the scope should be possible to make. \nThe scope may may also be implemented with language-specific features (e.g. annotations, struct-tags, etc.)\n\n### `compute_root(partial: Partial)`\n\nConstruct the hash-tree-root (or possibly signing-root); effectively computing the root of the proof-backing. Used for verification purposes.\n\nNote that there is no signing root function; a Partial without the last Container field can be used to ignore the last field. \nA proof can also not back both a signing-root and hash-tree-root unless the last field would be included as witness or leaf, which is handled better by scoping the type manually. \n\n## Read-only partials\n\nSome partials may not be meaningful to modify; in this case a proof-backing optimized for reads, and a read-only partial could be implemented.\n\n","topic":"partials"},{"data":"\n\n# Chunkify\n\n`chunks` are `Bytes32` intermediate merkle values, used for e.g. [subtree merkleization](./subtree_merkleization.md) leafs.\n\n## `chunkify` \n\n### Complex sequences\n\nSequences that are not homogeneously typed, or not of basic values or bits, are not packed.\nInstead, the `chunks` are the `hash_tree_root`s for each of the values.  \n\n### Basic sequences / bitfields\n\nTo convert a homogeneously typed sequence of basic values or bits into chunks, the values are packed.\n\nChunkification of `elements` of a sequence type `T` is defined as following:\n\n#### For basic elements:\n\nGiven ordered `elements` of the same basic type:\n - Partition the elements into chunks: split the elements in groups of consecutive `32 / size_of(B)` elements.\n    - The last partition may not be full.\n - Serialize the elements in each partition, and tightly pack the partition into a chunk (no padding between elements).\n    - If the last-partition is not full, it is right-padded with zero bytes.\n\n#### For bitfields\n\n - Serialize the Bitlist or bitvector.\n - The length-delimiting bit for bitlists is excluded: bitlists mix-in the bit-length and do not need the delimiting bit.\n - Right-pad the serialized bytes to a multiple of 32.\n - Partition into chunks: split the bytes into groups of consecutive `32` bytes\n\n## `chunk_count`\n\n`chunk_count(type)`: calculate the amount of leafs for merkleization of the type.\n * all basic types: `1`\n * `Bitlist[N]` and `Bitvector[N]`: `(N + 255) // 256` (dividing by chunk size, rounding up)\n * `List[B, N]` and `Vector[B, N]`, where `B` is a basic type: `(N * size_of(B) + 31) // 32` (dividing by chunk size, rounding up)\n * `List[C, N]` and `Vector[C, N]`, where `C` is a composite type: `N`\n * containers: `len(fields)`\n\n","topic":"chunkify"},{"data":"\n# Hashing\n\nSSZ utilizes the SHA-256 hash function.\n\nThe standard specification for SHA-256 can be found in [FIPS 180-4](https://csrc.nist.gov/publications/detail/fips/180/4/final).\n\n## Hashing primitive for binary trees.\n\n```\nH(a: bytes32, b: bytes32) -\u003e SHA_256(a ++ b)\n```\n\nWhere `++` is concatenation, i.e. tightly packing `a` and `b` into 64 bytes.\nAnd `SHA_256` is run on the standard unmodified pre-state, and returns the digest after writing and processing the above 64 bytes.\n\n## Zero-hashes\n\nA common occurrence in merkleization in SSZ is `H(X, H(0, 0)), H(X, H(H(0, 0), H(0, 0))), H(X, H(H(H(...`\n\nThe right-hand side here would be costly to merkleize leaf by leaf, but is efficiently precomputed, and referred to as a \"zero hash\" of some order N, starting from 0 being a bare zeroed `bytes32`:\n\n```\nZ[0]: 000000....   # a zeroed bytes32\nZ[1]: H(Z[0], Z[0])\nZ[2]: H(Z[1], Z[1])\nZ[2]: H(Z[1], Z[1])\nZ[3]: H(Z[2], Z[2])\n...\n```\n\n## Alternatives\n\nOther hash-functions have been considered for specific use cases, but are actively avoided for higher compatibility with other platforms, and more consistency.\n\n- 256 bits SHA-3 and Keccak were considered but dropped in favor of SHA-256 support and compatibility.\n- \"fast-SHA256\" as described in [BIP-98](https://github.com/bitcoin/bips/blob/master/bip-0098.mediawiki), optimized for two 32 byte inputs. But still a draft, and even more compatibility concerns.\n- A S\\[T/N]ARK-friendly hash function, the aim is to migrate in a future Eth2 deployment phase.\n","topic":"hashing"},{"data":"\n\n\n# Merkle proofs\n\n## For beginners\n\nMerkle proofs enable users to efficiently prove specific details of some data-structure that is known by a given hash.\n\nThe efficiency is achieved with a tree structure of hashes, with the data in the leaves of the tree.\nFor a proof of a set of leaves, branches to other leaves do not have to be fully encoded or hashed,\nthe starts of each such branch, together with the values to proof, are sufficient to reconstruct the root of the tree.\nCompare the reconstructed root with the trusted root the data is known by, and the proof is complete.\n\n## Accumulator \n\nMerkle trees are a type of cryptographic accumulator, and a root is a binding vector commitment to a set of contents.\nI.e. the position of the contents is also committed, not just inclusion. Changing the position of any of the contents would change the Merkle root.\n\nMembership of a leaf value, at a specific position, can be proven with witness data:\n a set of hashes along the way to the root of the tree, taking `O(log(N))` space and computation for a proof, as opposed to `N` for providing the full data.\n\n## Binary Merkle Tree\n\nThe tree structure itself affects the amount of nodes, and thus the amount of hash operations, and size of the proof.\n\nOne of the few opinionated choices made by SSZ for Eth2 is the choice for a **Binary Merkle Tree**, as oposed to Merkle Patricia Trees used in Eth1.\n\nBinary trees provide simplicity and efficiency:\n- No irregular branch structures\n- Any data structure can be translated to a binary tree with minimal effort.\n- Less proof witness data in favor of a few more hash operations\n- High affinity with bitfields for navigation and description\n- Enable a wide range of other binary-tree specific optimizations\n\n\n## Verification\n\nClaims for leaves of data can be verified by reconstructing the root from these leaves with the help of witness data:\nsibling nodes of the branches leading back to the root.\n\n\n### Multi-proof\n\nA multi-proof is no different than a regular proof other than proving multiple leaf values at the same time.\nNotice that leaf nodes that share the same subtrees also share more witness nodes, and are thus proven together more efficiently.\nSharing of witnesses in general is also more efficient than not sharing, as with individual leaf proofs.\n\n\n### Examples\n\nThe numbers used in below examples are [generalized indices](../navigation/generalized_indices.md), not values.\nNote that the ordering of witness data is an encoding choice, defined by the [proof backing](#proof-backings).\n\n#### Classic single-leaf inclusion proofs\n\n```\n                      1\n          2                       3'\n    4'          5           6           7\n  8    9     10'  11*    12   13     14   15 \n```\n\nLeaf: `11`\nWitness data: `10, 4, 3`\nProof: `H(H(4, H(10,11)), 3) == 1`\n\n#### Multiples leaves\n\nAlso called \"multi-proofs\".\n\n```\n                      1\n          2                       3\n    4'          5           6           7'\n  8    9     10*  11*    12'  13*    14   15\n```\n\nLeaves: `10,11,13`\nWitness data: `4, 12, 7`\nProof: `H(H(4, H(10,11)), H(H(12,13), 7)) == 1`\n\n#### Unbalanced trees\n\n\n```\n              1\n       2              3\n    4    5'        6       7'\n  8' 9*        12     13'\n            24'   25\n                50  51\n           100'101* 102*103*\n```\n\nLeaves: `9,101,102,103`\nWitness data: `8,524,100,13,7`\nProof: `H(H(H(8,9), 5),   H(H(  H(24, H(H(100,101), H(102, 103))),   13), 7)) == 1`\n\n\n## Proof backings\n\nA \"backing\" is the concept of a specialized binary tree representation that implements the Merkle proof interface,\n and optionally offer additional functionality like proof data lookups or modifications.\n\nFor an implementation, several choices can be made:\n- Ordering of leaf nodes and witness data\n- Ordering of operations to reconstruct the root, in case of multi-proofs.\n- Inclusion of a description of the proof target leaves, or the complete proof structure.\n- Optimizations for fast reading, verification or modifications to the proof.\n\nSSZ is agnostic to this: Merkle proofs are an interface to these backings, not an enshrined choice for one approach.\n\n\n## Interface\n\nFor application level usage, describing the proof with a typed structure is recommended, see [SSZ partials](../partials).\n\nFor lower level usage, most of the complexity (and implementation freedom) is transferred to the underlying proof backing, and only a bare minimum interface is defined:\n\n`compute_root(proof_backing) -\u003e root`\n\n`verify(proof_backing, root) -\u003e bool: return compute_root(proof_backing) == root`\n","topic":"merkle_proofs"},{"data":"\n\n# Merkle Mix-ins\n\nConstruct: `Mix(core, tag)`\n\nTo tag specific information (\"`tag`\" here) to a root value (\"`core`\"), e.g. a length of the contents the `core` represents.\n\nThis merkleization step is simply: `H(core, tag)`, with both inputs left-padded to to a full 32 bytes.\n\nSSZ is consistent with merkleizing in these tags to the right: it avoids a kink of branch nodes in common proof encodings.\nI.e. the left-most contents value and its branch of witness nodes go straight to the root.  \n\nIn the spec the following function definition is used when mixing in a number:\n\n__`mix_in_num(root, num)`__: Given a `root` and a `num` (`\"uint256\"` little-endian serialization) return `hash(root ++ num)` (the `++` is concatenation).\n","topic":"mixin"},{"data":"\n\n# Subtree Merkleization\n\nMerkleization does not have to be irregular, many types are designed to map to a stable complete tree.\n\nSubtree merkleization `merkle_subtree(chunks, limit=None)` (see [chunkification](./chunkify.md)) is defined with the following functions:\n\n* `next_pow_of_two(i)`: get the next power of 2 of `i`, if not already a power of 2, with 0 mapping to 1. Examples: `0-\u003e1, 1-\u003e1, 2-\u003e2, 3-\u003e4, 4-\u003e4, 6-\u003e8, 9-\u003e16`\n* __`merkle_subtree(chunks, limit=None)`__: Given ordered chunks, merkleize the chunks, and return the root:\n    * The merkleization depends on the effective input, which can be padded/limited:\n        - if no limit: pad the `chunks` with zeroed chunks to `next_pow_of_two(len(chunks))` (virtually for memory efficiency).\n        - if `limit \u003e len(chunks)`, pad the `chunks` with zeroed chunks to `next_pow_of_two(limit)` (virtually for memory efficiency).\n        - if `limit \u003c len(chunks)`: do not merkleize, input exceeds limit. Raise an error instead.\n        - if `limit == len(chunks)`: no-op, chunks have exactly the right length already.\n    * Then, merkleize the chunks (empty input is padded to 1 zero chunk):\n        - If `1` chunk: the root is the chunk itself.\n        - If `\u003e 1` chunks: merkleize as binary tree.\n\nFor virtual padding, two subtrees of zero-padding merkleize into a pre-computable [zero-hash](./hashing.md#zero-hashes). \n","topic":"subtree_merkleization"},{"data":"\n\n# Classic merkle proof backing\n\nThis format is not optimal for newer multi-proof use cases, but does offer:\n- Simplicity\n- Backwards compatibility\n- Consistency with regular single-leaf merkle proofs\n \n## Contents\n\n- Description: Generalized indices of the leaves `[optional]`\n- Leaf data: Leaf chunks `[optional]`\n- Witness data: Witness chunks\n\nThe separation of content types, and the order of the chunks in the witness data, makes a the backing encoding compatible with a standard single leaf merkle proof. top-to-bottom branch \n\n### Description\n \nThe description of contents is kept separate from the actual witness data, and an optional part of the format:\n if the both the proof producing party and and proof consuming part have the same expectation of contents, there is no need to repeat it in communication.\n\nAlso this fits with the existing convention for Merkle proofs where the index is separate from the proof.\n\n#### Helper indices\n\nThe generalized indices of the witness data (the \"helper indices\") can be derived from those of the leaves, and are thus not encoded.\nThe below Python code demonstrates how this can be done:\n\n```python\ndef get_branch_indices(tree_index: GeneralizedIndex) -\u003e Sequence[GeneralizedIndex]:\n    \"\"\"\n    Get the generalized indices of the sister chunks along the path from the chunk with the\n    given tree index to the root.\n    \"\"\"\n    o = [generalized_index_sibling(tree_index)]\n    while o[-1] \u003e 1:\n        o.append(generalized_index_sibling(generalized_index_parent(o[-1])))\n    return o[:-1]\n```\n\n```python\ndef get_path_indices(tree_index: GeneralizedIndex) -\u003e Sequence[GeneralizedIndex]:\n    \"\"\"\n    Get the generalized indices of the chunks along the path from the chunk with the\n    given tree index to the root.\n    \"\"\"\n    o = [tree_index]\n    while o[-1] \u003e 1:\n        o.append(generalized_index_parent(o[-1]))\n    return o[:-1]\n```\n\n```python\ndef get_helper_indices(indices: Sequence[GeneralizedIndex]) -\u003e Sequence[GeneralizedIndex]:\n    \"\"\"\n    Get the generalized indices of all \"extra\" chunks in the tree needed to prove the chunks with the given\n    generalized indices. Note that the decreasing order is chosen deliberately to ensure equivalence to the\n    order of hashes in a regular single-item Merkle proof in the single-item case.\n    \"\"\"\n    all_helper_indices: Set[GeneralizedIndex] = set()\n    all_path_indices: Set[GeneralizedIndex] = set()\n    for index in indices:\n        all_helper_indices = all_helper_indices.union(set(get_branch_indices(index)))\n        all_path_indices = all_path_indices.union(set(get_path_indices(index)))\n\n    return sorted(all_helper_indices.difference(all_path_indices), reverse=True)\n```\n\n#### Leaf Indices\n\nThe positions of the leaves are encoded in bit-alphabetical left-to-right order:\n\n```python\ndef split_by_root(ints, depth):\n    t, l, r = [], [], []\n    for i in ints:\n        if i.bit_length() \u003c depth:\n            t.append(i)\n        elif (i \u003e\u003e (i.bit_length() - depth)) % 2 == 1:\n            r.append(i)\n        else:\n            l.append(i)\n    return t, l, r\n\ndef alphasort(ints, depth=2):\n    if len(ints) \u003c= 1:\n        return ints\n    t, l, r = split_by_root(ints, depth)\n    return t + alphasort(l, depth+1) + alphasort(r, depth+1)\n```\n\n##### Example\n\n```\nTree:\n   1\n 2   3 \n4 5 6 7\n\n\u003e\u003e\u003e alphasort([1,2,3,4,5,6,7])\n[1, 2, 4, 5, 3, 6, 7]\n```\n\nNote that not all generalized indices would be encoded, only those of the leaves the proof is targetting.\nThose that do get encoded will be ordered correctly for a single-pass left-to-right tree traversal for verification.\n\n### Leaf data\n\nThe leaf data is optional because in some cases the leaf data may also be known by both parties, or encoded elsewhere outside of the proof.\n\nThe 32 byte chunks of data are ordered the same as the leaf indices of the description part are.\n\n### Witness data\n\nWitness data is the essential part of the proof, and kept separate from the leaf data.\n\nLike leaf data, witness data is also sorted in bit-alphabetical left-to-right order (in respect to the generalized indices matching the chunks).\n\n## Verification\n\n```python\ndef calculate_multi_merkle_root(leaves: Sequence[Bytes32],\n                                proof: Sequence[Bytes32],\n                                indices: Sequence[GeneralizedIndex]) -\u003e Bytes32:\n    assert len(leaves) == len(indices)\n    helper_indices = get_helper_indices(indices)\n    assert len(proof) == len(helper_indices)\n    objects = {\n        **{index: node for index, node in zip(indices, leaves)},\n        **{index: node for index, node in zip(helper_indices, proof)}\n    }\n    keys = sorted(objects.keys(), reverse=True)\n    pos = 0\n    while pos \u003c len(keys):\n        k = keys[pos]\n        if k in objects and k ^ 1 in objects and k // 2 not in objects:\n            objects[GeneralizedIndex(k // 2)] = hash(\n                objects[GeneralizedIndex((k | 1) ^ 1)] +\n                objects[GeneralizedIndex(k | 1)]\n            )\n            keys.append(GeneralizedIndex(k // 2))\n        pos += 1\n    return objects[GeneralizedIndex(1)]\n```\n\n```python\ndef verify_merkle_multiproof(leaves: Sequence[Bytes32],\n                             proof: Sequence[Bytes32],\n                             indices: Sequence[GeneralizedIndex],\n                             root: Hash) -\u003e bool:\n    return calculate_multi_merkle_root(leaves, proof, indices) == root\n```\n\nA challenge for the reader now, but planned as appendix to this spec,\n is to write an optimized single-pass stack based merkleization alternative.\nSince even for a multi-proof, it is not necessary to buffer too much at once.\n ","topic":"proof_backings/classic"},{"data":"\n\n# Generalized Merkle tree index\n\nThe hash-tree-root of all SSZ types merkleizes the contents as a binary tree.\nIn such a binary tree, the path to any node from the root can be described by a bitfield.\n\nThis bitfield can also be expressed as an integer, called a \"generalized index\" in SSZ.\nThe generalized index value for a node in a binary tree is `2**depth + index`, starting with a 1 for the root.\nVisually, this looks as follows:\n\n```\n    1\n 2     3\n4 5   6 7\n   ...\n``` \n\nLike the bitfield form that is extended with a `0` or `1` for each child,\n the generalized index has the convenient property that the two children of node `k` are `2k` and `2k+1`.\n\n## Combination and slicing\n\nTo navigate from `A` to `B` to `C`, where `B` is in the subtree of `A` and `C` in the subtree of `B`, the generalized indices can be composed and sliced:\n\nA generalized index is composed of a leading bit `1` for the root, and the remainder navigates the path in binary tree.\n\nThese navigation parts `AB` and `BC` can be concatenated to get the navigation part `AC`: `AB ++ BC \u003c-\u003e AC`.\nAnd then a `1` is prepended again to delimit the exact length of the path and represent the root.  \n\n\n## Flat indexing\n \nFor implementation purposes, the generalized index matches the position of a node in the linear representation of the Merkle tree, as computed by this function:\n\n```python\ndef merkle_tree(leaves: Sequence[Bytes32]) -\u003e Sequence[Bytes32]:\n    padded_length = get_next_power_of_two(len(leaves))\n    o = [Bytes32()] * padded_length + list(leaves) + [Bytes32()] * (padded_length - len(leaves))\n    for i in range(padded_length - 1, 0, -1):\n        o[i] = hash(o[i * 2] + o[i * 2 + 1])\n    return o\n```\n\n## Representation\n\nIn the SSZ spec, a generalized index is represented as a custom integer type: `GeneralizedIndex` (of arbitrary bitlength).\nIt can be also be represented as a Bitvector/Bitlist object.\n\nNote that for bitfields, the root bit is not encoded in SSZ:\n- bitlists: SSZ already naturally appends 1 to the serialized bits, to make a difference in bitlengths.\n- bitvectors: vectors are of fixed length, and do not need the delimiting bit.\n","topic":"generalized_indices"},{"data":"\n\n# Paths\n\nPaths are the human-readable variant of [Generalized Indices](./generalized_indices.md).\nTo make paths human-readable, and derive SSZ properties like generalized indices, type information is required.\n\n## Syntax \n\nThe human-readable form is simply a `/`-separated list of path components, starting with the name of the root type.\n\nExample:\n```\nMyType/some_field/abc_list/123/foobar\n```\n\nLanguages may have different levels of expressiveness for these type of paths, and static languages may require templates or code-generation for this.\n\nThe Python-like SSZ spec overloads the `/` operator to present paths:\n\n```python\nssz_path(MyType) / 'some_field' / 'abc_list' / 123 / 'foobar'\n```\n\n`ssz_path(ssz_type)` here creates a root path element (type `Path`), to separate path logic from the root (`MyType` here) itself.\n\n`Path` objects can also be appended to other paths, but only if the type of the root matches the type of the leaf we are appending to:\n\n```\na = ssz_path(MyType) / 'some_field' / 'abc_list'\na.leaf_type() == AbcListType\n\nb = ssz_path(AbcListType) / 123 / 'foobar'\n\ncombined = a / b\ncombined == ssz_path(MyType) / 'some_field' / 'abc_list' / 123 / 'foobar'\n```\n\n## Interface\n\nTyped paths offer the following interface:\n\n`.leaf_type()`: get the type of the end (leaf) of the path.\n`.root_type()`: get the type of the start (root) of the path.\n`.parent()`: get the path, without the last component (leaf).\n`.generalized_index()`: get the generalized index of the path.\n\n## Paths\n\nPaths are the preferred form to express accesses of leaf values in source code:\n in the rare event of changes to a SSZ type (e.g. a fork), \n the amount of fields or elements may not be the same, and change the generalized index.\nThis would break a generalized index, but not the path.\n\nHowever, such changes should be avoided, or prepared for by padding the type (and thus reserving the merkleization space for expected future changes).\n\n","topic":"paths"},{"data":"\n\n# Summaries \u0026 Expansions\n\nLet `A` be an object derived from another object `B` by replacing some of the (possibly nested) values of `B` by their `hash_tree_root`.\nBecause of this substitution, `hash_tree_root(A) == hash_tree_root(B)`.\n\nWe say `A` is a **\"summary\"** of `B`, and that `B` is an **\"expansion\"** of `A`. The replaced values are the **\"details\"** of `B` with respect to `A`.\n\nSummary instances expand to at most one instance of a given expansion: \n the detail of the summary is a strict subset of that of the expansion and the difference cannot be altered without changing the summary root.\n\n## Transparency \n\nNot all expansions may be defined ahead of time; SSZ does not limit a root to be expanded into more detail.\n\nThis is a pathway for different use-cases:\n- Forward-compatible hash-tree-roots: a summary definition can stay unaltered when an expansion definition is changed.\n- Merkle proofs can navigate as far as roots can be expanded:\n    - State roots, crosslink-data roots, block roots and any system root can be taken and expanded, and their data can be too.\n      All system data can be proven through a single merkle proof one way or another.\n    - User-level roots (e.g. beacon block graffiti) may also be given user-level expansion definitions to soft-fork in new functionality.\n\nWarning: this is all safe when working with static expansion definitions, but pre-image attacks should be considered when working with dynamic expansions.\nSomeone may exploit an unexpected expansion, e.g. querying a binary path beyond the intended depth. See types below to avoid such arbitrary expansions.\n\n## As types\n\nA summary type can be defined by taking the expansion and substituting the types of the elements to summarize with `Bytes32` to reflect their `hash_tree_root`.\nOr vice versa an expansion can be defined based on a summary type.\n\nSome details can also be summarized with a `signing_root`. An implementer has two options here:\n1. Ignore the final signature field, the root of this container in the summary type can be annotated to do this.\n2. Exclude the signature field from the expansion definition to begin with.\n\n### Example\n\nIn the Eth2 beacon chain, a [`BeaconBlock`](https://github.com/ethereum/eth2.0-specs/blob/master/specs/core/0_beacon-chain.md#beaconblock)\nis an expansion type of [`BeaconBlockHeader`](https://github.com/ethereum/eth2.0-specs/blob/master/specs/core/0_beacon-chain.md#beaconblockheader).\nNote that a `BeaconBlockHeader` objects uniquely expands to a `BeaconBlock` object.\n","topic":"summaries_expansions"}]},"__N_SSG":true},"page":"/altwalk","query":{},"buildId":"DlB46tPebyHRLgflZjsgq","isFallback":false,"gsp":true}</script><script nomodule="" src="/_next/static/chunks/polyfills-6e054d56079d4b93ebe8.js"></script><script src="/_next/static/chunks/webpack-50207a9308fa24ceece0.js" async=""></script><script src="/_next/static/chunks/framework-106d25c2ed81dc45938c.js" async=""></script><script src="/_next/static/chunks/main-1edd7ef5819b2a11bbed.js" async=""></script><script src="/_next/static/chunks/pages/_app-067f3f505bf9f3e67d67.js" async=""></script><script src="/_next/static/chunks/9282-be3425a58587a45a3808.js" async=""></script><script src="/_next/static/chunks/7507-81af9623502386b8c24a.js" async=""></script><script src="/_next/static/chunks/5835-a34425b363ee7a543e5a.js" async=""></script><script src="/_next/static/chunks/7467-8b8ea4cfd89ac7664267.js" async=""></script><script src="/_next/static/chunks/9238-a3fd48a971513fe11c50.js" async=""></script><script src="/_next/static/chunks/8075-48adf4f568d38ee91732.js" async=""></script><script src="/_next/static/chunks/2852-de21a24c1010e6297a46.js" async=""></script><script src="/_next/static/chunks/8151-b7f0693b6af81db553cf.js" async=""></script><script src="/_next/static/chunks/115-1251df7fc586bb041c3f.js" async=""></script><script src="/_next/static/chunks/pages/altwalk-7cbb331762e92c9aadad.js" async=""></script><script src="/_next/static/DlB46tPebyHRLgflZjsgq/_buildManifest.js" async=""></script><script src="/_next/static/DlB46tPebyHRLgflZjsgq/_ssgManifest.js" async=""></script></body></html>