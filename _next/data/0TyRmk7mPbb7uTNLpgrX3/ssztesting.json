{"pageProps":{"ssz_generic":"# SSZ, generic tests\n\nThis set of test-suites provides general testing for SSZ:\n to decode any container/list/vector/other type from binary data, encode it back, and compute the hash-tree-root.\n\nThis test collection for general-purpose SSZ is experimental.\nThe `ssz_static` suite is the required minimal support for SSZ, and should be prioritized.\n\nThe `ssz_generic` tests are split up into different handler, each specialized into a SSZ type:\n\n- Vectors\n    - `basic_vector`\n    - `complex_vector` *not supported yet*\n- List\n    - `basic_list` *not supported yet*\n    - `complex_list` *not supported yet*\n- Bitfields\n    - `bitvector`\n    - `bitlist`\n- Basic types\n    - `boolean`\n    - `uints`\n- Containers\n    - `containers`\n\n\n## Format\n\nFor each type, a `valid` and an `invalid` suite is implemented.\nThe cases have the same format, but those in the `invalid` suite only declare a subset of the data a test in the `valid` declares.\n\nEach of the handlers encodes the SSZ type declaration in the file-name. See [Type Declarations](#type-declarations).\n\n### `valid`\n\nValid has 3 parts: `meta.yaml`, `serialized.ssz_snappy`, `value.yaml`\n\n### `meta.yaml`\n\nValid ssz objects can have a hash-tree-root.\nThe expected roots are encoded into the metadata yaml:\n\n```yaml\nroot: Bytes32             -- Hash-tree-root of the object\n```\n\nThe `Bytes32` is encoded as a string, hexadecimal encoding, prefixed with `0x`.\n\n### `serialized.ssz_snappy`\n\nThe serialized form of the object, as snappy-compressed SSZ bytes.\n\n### `value.yaml`\n\nThe object, encoded as a YAML structure. Using the same familiar encoding as YAML data in the other test suites.\n\n### Conditions\n\nThe conditions are the same for each type:\n\n- Encoding: After encoding the given `value` object, the output should match `serialized`.\n- Decoding: After decoding the given `serialized` bytes, it should match the `value` object. \n- Hash-tree-root: the root should match the root declared in the metadata.\n\n## `invalid`\n\nTest cases in the `invalid` suite only include the `serialized.ssz_snappy`\n\n#### Condition\n\nUnlike the `valid` suite, invalid encodings do not have any `value` or hash tree root.\nThe `serialized` data should simply not be decoded without raising an error.\n\nNote that for some type declarations in the invalid suite, the type itself may technically be invalid.\nThis is a valid way of detecting `invalid` data too. E.g. a 0-length basic vector.\n\n\n## Type declarations\n\nMost types are not as static, and can reasonably be constructed during test runtime from the test case name.\nFormats are listed below.\n\nFor each test case, an additional `_{extra...}` may be appended to the name,\n where `{extra...}` contains a human readable indication of the test case contents for debugging purposes.\n\n### `basic_vector`\n\n```\nTemplate:\n\nvec_{element type}_{length}\n\nData:\n\n{element type}: bool, uint8, uint16, uint32, uint64, uint128, uint256\n\n{length}: an unsigned integer\n```\n\n\n### `bitlist`\n\n```\nTemplate:\n\nbitlist_{limit}\n\nData:\n\n{limit}: the list limit, in bits, of the bitlist. Does not include the length-delimiting bit in the serialized form.\n```\n\n\n### `bitvector`\n\n```\nTemplate:\n\nbitvec_{length}\n\nData:\n\n{length}: the length, in bits, of the bitvector.\n```\n\n### `boolean`\n\nA boolean has no type variations. Instead, file names just plainly describe the contents for debugging.\n\n### `uints`\n\n```\nTemplate:\n\nuint_{size}\n\nData:\n\n{size}: the uint size: 8, 16, 32, 64, 128 or 256.\n```\n\n### `containers`\n\nContainers are more complicated than the other types. Instead, a set of pre-defined container structures is referenced:\n\n```\nTemplate:\n\n{container name}\n\nData:\n\n{container name}: Any of the container names listed below (excluding the `(Container)` python super type)\n```\n\n```python\n\nclass SingleFieldTestStruct(Container):\n    A: byte\n\n\nclass SmallTestStruct(Container):\n    A: uint16\n    B: uint16\n\n\nclass FixedTestStruct(Container):\n    A: uint8\n    B: uint64\n    C: uint32\n\n\nclass VarTestStruct(Container):\n    A: uint16\n    B: List[uint16, 1024]\n    C: uint8\n\n\nclass ComplexTestStruct(Container):\n    A: uint16\n    B: List[uint16, 128]\n    C: uint8\n    D: Bytes[256]\n    E: VarTestStruct\n    F: Vector[FixedTestStruct, 4]\n    G: Vector[VarTestStruct, 2]\n\n\nclass BitsStruct(Container):\n    A: Bitlist[5]\n    B: Bitvector[2]\n    C: Bitvector[1]\n    D: Bitlist[6]\n    E: Bitvector[8]\n```\n","ssz_static":"# Test format: SSZ static types\n\nThe goal of this type is to provide clients with a solid reference for how the known SSZ objects should be encoded.\nEach object described in the Phase 0 spec is covered.\nThis is important, as many of the clients aiming to serialize/deserialize objects directly into structs/classes\ndo not support (or have alternatives for) generic SSZ encoding/decoding.\n\nThis test-format ensures these direct serializations are covered.\n\nNote that this test suite does not cover the invalid-encoding case:\n SSZ implementations should be hardened against invalid inputs with the other SSZ tests as guide, along with fuzzing.\n\n## Test case format\n\nEach SSZ type is a `handler`, since the format is semantically different: the type of the data is different.\n\nOne can iterate over the handlers, and select the type based on the handler name.\nSuites are then the same format, but each specialized in one randomization mode.\nSome randomization modes may only produce a single test case (e.g. the all-zeroes case).\n\nThe output parts are: `roots.yaml`, `serialized.ssz_snappy`, `value.yaml`\n\n### `roots.yaml`\n\n```yaml\nroot: bytes32         -- string, hash-tree-root of the value, hex encoded, with prefix 0x\n```\n\n### `serialized.ssz_snappy`\n\nThe SSZ-snappy encoded bytes.\n\n### `value.yaml`\n\nThe same value as `serialized.ssz_snappy`, represented as YAML.\n\n\n## Condition\n\nA test-runner can implement the following assertions:\n- If YAML decoding of SSZ objects is supported by the implementation:\n    - Serialization: After parsing the `value`, SSZ-serialize it: the output should match `serialized`\n    - Deserialization: SSZ-deserialize the `serialized` value, and see if it matches the parsed `value`\n- If YAML decoding of SSZ objects is not supported by the implementation:\n    - Serialization in 2 steps: deserialize `serialized`, then serialize the result, \n       and verify if the bytes match the original `serialized`.\n- Hash-tree-root: After parsing the `value` (or deserializing `serialized`), Hash-tree-root it: the output should match `root`\n\n\n## References\n\n**`serialized`**—[SSZ serialization](../../../ssz/simple-serialize.md#serialization)\n**`root`**—[hash_tree_root](../../../ssz/simple-serialize.md#merkleization) function\n","eth2TestFormat":"# General test format\n\nThis document defines the YAML format and structure used for Eth2 testing.\n\n## Table of contents\n<!-- TOC -->\n\n* [About](#about)\n  + [Test-case formats](#test-case-formats)\n* [Glossary](#glossary)\n* [Test format philosophy](#test-format-philosophy)\n  + [Config design](#config-design)\n  + [Test completeness](#test-completeness)\n* [Test structure](#test-structure)\n  + [`<config name>/`](#--config-name---)\n  + [`<fork or phase name>/`](#--fork-or-phase-name---)\n  + [`<test runner name>/`](#--test-runner-name---)\n  + [`<test handler name>/`](#--test-handler-name---)\n  + [`<test suite name>/`](#--test-suite-name---)\n  + [`<test case>/`](#--test-case---)\n  + [`<output part>`](#--output-part--)\n    - [Special output parts](#special-output-parts)\n      * [`meta.yaml`](#-metayaml-)\n* [Config](#config)\n* [Config sourcing](#config-sourcing)\n* [Note for implementers](#note-for-implementers)\n\n<!-- /TOC -->\n\n## About\n\nEthereum 2.0 uses YAML as the format for all cross client tests. This document describes at a high level the general format to which all test files should conform.\n\n### Test-case formats\n\nThe particular formats of specific types of tests (test suites) are defined in separate documents.\n\nTest formats:\n- [`bls`](./bls/README.md)\n- [`epoch_processing`](./epoch_processing/README.md)\n- [`genesis`](./genesis/README.md)\n- [`operations`](./operations/README.md)\n- [`sanity`](./sanity/README.md)\n- [`shuffling`](./shuffling/README.md)\n- [`ssz_generic`](./ssz_generic/README.md)\n- [`ssz_static`](./ssz_static/README.md)\n- More formats are planned, see tracking issues for CI/testing\n\n\n## Glossary\n\n- `generator`: a program that outputs one or more test-cases, each organized into a `config > runner > handler > suite` hierarchy.\n- `config`: tests are grouped by configuration used for spec presets. In addition to the standard configurations, \n  `general` may be used as a catch-all for tests not restricted to one configuration. (E.g. BLS).\n- `type`: the specialization of one single `generator`. E.g. epoch processing.\n- `runner`: where a generator is a *\"producer\"*, this is the *\"consumer\"*.\n  - A `runner` focuses on *only one* `type`, and each type has *only one* `runner`.\n- `handler`: a `runner` may be too limited sometimes, you may have a set of tests with a specific focus that requires a different format.\n  To facilitate this, you specify a `handler`: the runner can deal with the format by using the specified handler.\n- `suite`: a directory containing test cases that are coherent. Each `suite` under the same `handler` shares the same format.\n  This is an organizational/cosmetic hierarchy layer.\n- `case`: a test case, a directory in a `suite`. A case can be anything in general, \n  but its format should be well-defined in the documentation corresponding to the `type` (and `handler`).\n- `case part`: a test case consists of different files, possibly in different formats, to facilitate the specific test case format better.\n  Optionally, a `meta.yaml` is included to declare meta-data for the test, e.g. BLS requirements. \n\n## Test format philosophy\n\n### Config design\n\nThe configuration constant types are:\n- Never changing: genesis data.\n- Changing, but reliant on old value: e.g. an epoch time may change, but if you want to do the conversion \n  `(genesis data, timestamp) -> epoch number`, you end up needing both constants.\n- Changing, but kept around during fork transition: finalization may take a while,\n  e.g. an executable has to deal with new deposits and old deposits at the same time. Another example may be economic constants.\n- Additional, backwards compatible: new constants are introduced for later phases.\n- Changing: there is a very small chance some constant may really be *replaced*. \n  In this off-chance, it is likely better to include it as an additional variable,\n  and some clients may simply stop supporting the old one if they do not want to sync from genesis.\n  The change of functionality goes through a phase of deprecation of the old constant, and eventually only the new constant is kept around in the config (when old state is not supported anymore).\n\nBased on these types of changes, we model the config as a list of key value pairs,\n that only grows with every fork (they may change in development versions of forks, however; git manages this).\nWith this approach, configurations are backwards compatible (older clients ignore unknown variables) and easy to maintain.\n\n### Test completeness\n\nTests should be independent of any sync-data. If one wants to run a test, the input data should be available from the YAML.\nThe aim is to provide clients with a well-defined scope of work to run a particular set of test-suites.\n\n- Clients that are complete are expected to contribute to testing, seeking for better resources to get conformance with the spec, and other clients.\n- Clients that are not complete in functionality can choose to ignore suites that use certain test-runners, or specific handlers of these test-runners.\n- Clients that are on older versions can test their work based on older releases of the generated tests, and catch up with newer releases when possible.\n\n\n## Test structure\n\n```\nFile path structure:\ntests/<config name>/<fork or phase name>/<test runner name>/<test handler name>/<test suite name>/<test case>/<output part>\n```\n\n### `<config name>/`\n\nConfigs are upper level. Some clients want to run minimal first, and useful for sanity checks during development too.\nAs a top level dir, it is not duplicated, and the used config can be copied right into this directory as reference.\n\n### `<fork or phase name>/`\n\nThis would be: \"phase0\", \"altair\", etc. Each introduces new tests, and modifies any tests that change:\nsome tests of earlier forks repeat with updated state data.\n\n### `<test runner name>/`\n\nThe well known bls/shuffling/ssz_static/operations/epoch_processing/etc. Handlers can change the format, but there is a general target to test.\n\n\n### `<test handler name>/`\n\nSpecialization within category. All suites in here will have the same test case format.\nUsing a `handler` in a `runner` is optional. A `core` (or other generic) handler may be used if the `runner` does not have different formats.\n\n### `<test suite name>/`\n\nSuites are split up. Suite size (i.e. the amount of tests) does not change the maximum memory requirement, as test cases can be loaded one by one.\nThis also makes filtered sets of tests fast and easy to load.\n\n### `<test case>/`\n\nCases are split up too. This enables diffing of parts of the test case, tracking changes per part, while still using LFS. Also enables different formats for some parts.\n\n### `<output part>`\n\nThese files allow for custom formats for some parts of the test. E.g. something encoded in SSZ.\nOr to avoid large files, the SSZ can be compressed with Snappy.\nE.g. `pre.ssz_snappy`, `deposit.ssz_snappy`, `post.ssz_snappy`.\n\nDiffing a `pre.ssz_snappy` and `post.ssz_snappy` provides all the information for testing, when decompressed and decoded.\nThen the difference between pre and post can be compared to anything that changes the pre state, e.g. `deposit.ssz_snappy`\n\nNote that by default, the SSZ data is in the given test case's <fork or phase name> version, e.g., if it's `altair` test case, use `altair.BeaconState` container to deserialize the given state.\n\nYAML is generally used for test metadata, and for tests that do not use SSZ: e.g. shuffling and BLS tests.\nIn this case, there is no point in adding special SSZ types. And the size and efficiency of YAML is acceptable.\n\n#### Common output formats\n\nBetween all types of tests, a few formats are common:\n\n- **`.yaml`**: A YAML file containing structured data to describe settings or test contents.\n- **`.ssz`**: A file containing raw SSZ-encoded data. Previously widely used in tests, but replaced with compressed variant.\n- **`.ssz_snappy`**: Like `.ssz`, but compressed with Snappy block compression.\n  Snappy block compression is already applied to SSZ in Eth2 gossip, available in client implementations, and thus chosen as compression method.\n\n\n#### Special output parts\n\n##### `meta.yaml`\n\nIf present (it is optional), the test is enhanced with extra data to describe usage. Specialized data is described in the documentation of the specific test format. \n\nCommon data is documented here:\n\nSome test-case formats share some common key-value pair patterns, and these are documented here:\n\n```\nbls_setting: int     -- optional, can have 3 different values:\n                            0: (default, applies if key-value pair is absent). Free to choose either BLS ON or OFF.\n                                 Tests are generated with valid BLS data in this case,\n                                 but there is no change of outcome when running the test if BLS is ON or OFF.\n                            1: known as \"BLS required\" - if the test validity is strictly dependent on BLS being ON\n                            2: known as \"BLS ignored\"  - if the test validity is strictly dependent on BLS being OFF\nreveal_deadlines_setting:   -- optional, can have 2 different values:\n                            0: default, `process_reveal_deadlines` is ON.\n                            1: `process_reveal_deadlines` is OFF.\n```\n\n##### `config.yaml`\n\nThe runtime-configurables may be different for specific tests.\nWhen present, this replaces the default runtime-config that comes with the otherwise compile-time preset settings.\n\nThe format matches that of the `mainnet_config.yaml` and `minimal_config.yaml`,\nsee the [`/configs`](../../configs/README.md#format) documentation.\nConfig values that are introduced at a later fork may be omitted from tests of previous forks.\n\n\n## Config sourcing\n\nThe constants configurations are located in:\n\n```\n<specs repo root>/configs/<config name>.yaml\n```\n\nAnd copied by CI for testing purposes to:\n\n```\n<tests repo root>/tests/<config name>/<config name>.yaml\n```\n\nThe first `<config name>` is a directory, which contains exactly all tests that make use of the given config.\n\n\n## Note for implementers\n\nThe basic pattern for test-suite loading and running is:\n\n1. For a specific config, load it first (and only need to do so once),\n    then continue with the tests defined in the config folder.\n2. Select a fork. Repeat for each fork if running tests for multiple forks.  \n3. Select the category and specialization of interest (e.g. `operations > deposits`). Again, repeat for each if running all.\n4. Select a test suite. Or repeat for each.\n5. Select a test case. Or repeat for each.\n6. Load the parts of the case. And `meta.yaml` if present.\n7. Run the test, as defined by the test format.\n\nStep 1 may be a step with compile time selection of a configuration, if desired for optimization.\nThe base requirement is just to use the same set of constants, independent of the loading process. \n","eth2TestSpec":"# Eth2 Executable Python Spec (PySpec)\n\nThe executable Python spec is built from the Eth2 specification, \n complemented with the necessary helper functions for hashing, BLS, and more.\n\nWith this executable spec,\n test-generators can easily create test-vectors for client implementations,\n and the spec itself can be verified to be consistent and coherent through sanity tests implemented with pytest.\n\n## Dev Install\n\nFirst, create a `venv` and install the developer dependencies (`test` and `lint` extras):\n\n```shell\nmake install_test\n```\n\nAll the dynamic parts of the spec are built with:\n\n```shell\n(venv) python setup.py pyspecdev\n```\n\nUnlike the regular install, this outputs spec files to their intended source location,\nto enable debuggers to navigate between packages and generated code, without fragile directory linking.\n\nBy default, when installing the `eth2spec` as package in non-develop mode,\nthe distutils implementation of the `setup` runs `build`, which is extended to run the same `pyspec` work,\nbut outputs into the standard `./build/lib` output.\nThis enables the `eth2.0-specs` repository to be installed like any other python package.\n\n\n## Py-tests\n\nThese tests are not intended for client-consumption.\nThese tests are testing the spec itself, to verify consistency and provide feedback on modifications of the spec.\nHowever, most of the tests can be run in generator-mode, to output test vectors for client-consumption.\n\n### How to run tests\n\n#### Automated\n\nRun `make test` from the root of the specs repository (after running `make install_test` if have not before).\n\nNote that the `make` commands run through the build steps: it runs the `build` output, not the local package source files.\n\n#### Manual\n\nSee `Dev install` for test pre-requisites.\n\nTests are built for `pytest`.\n\nCaveats:\n- Working directory must be `./tests/core/pyspec`. The work-directory is important to locate eth2 configuration files.\n- Run `pytest` as module. It avoids environment differences, and the behavior is different too:\n  `pytest` as module adds the current directory to the `sys.path`\n\nFull test usage, with explicit configuration for illustration of options usage:\n```shell\n(venv) python -m pytest --preset=minimal eth2spec\n```\n\nOr, to run a specific test file, specify the full path:\n```shell\n(venv) python -m pytest --preset=minimal ./eth2spec/test/phase0/block_processing/test_process_attestation.py\n```\n\nOr, to run a specific test function (specify the `eth2spec` module, or the script path if the keyword is ambiguous):\n```shell\n(venv) python -m pytest --preset=minimal -k test_success_multi_proposer_index_iterations eth2spec\n```\n\nOptions:\n- `--preset`, to change the preset (compile-time configurables). Defaults to `minimal`, can be set to `mainnet`.\n  Use `@spec_configured_state_test({config here...}` to override runtime configurables on a per-test basis.\n- `--disable-bls`, to disable BLS (only for tests that can run without)\n- `--bls-type`, `milagro` or `py_ecc` (default)\n\n### How to view code coverage report\n\nRun `make open_cov` from the root of the specs repository after running `make test` to open the html code coverage report.\n\n### Advanced\n\nBuilding spec files from any markdown sources, to a custom location:\n```bash\n(venv) python setup.py pyspec --spec-fork=phase0 --md-doc-paths=\"specs/phase0/beacon-chain.md specs/phase0/fork-choice.md\" --out-dir=my_spec_dir\n```\n\n## Contributing\n\nContributions are welcome, but consider implementing your idea as part of the spec itself first.\nThe pyspec is not a replacement.\n\n\n## License\n\nSame as the spec itself; see [LICENSE](../../../LICENSE) file in the specs repository root.\n"},"__N_SSG":true}