{"pageProps":{"SpecsData":"# SimpleSerialize (SSZ)\n\n## Constants\n\n| Name                      | Value | Description                                   |\n| ------------------------- | ----- | --------------------------------------------- |\n| `BYTES_PER_CHUNK`         | `32`  | Number of bytes per chunk.                    |\n| `BYTES_PER_LENGTH_OFFSET` | `4`   | Number of bytes per serialized length offset. |\n| `BITS_PER_BYTE`           | `8`   | Number of bits per byte.                      |\n\n## Typing\n\n### Basic types\n\n- `uintN`: `N`-bit unsigned integer (where `N in [8, 16, 32, 64, 128, 256]`)\n- `boolean`: `True` or `False`\n\n### Composite types\n\n- **container**: ordered heterogeneous collection of values\n  - python dataclass notation with key-type pairs, e.g.\n  ```python\n  class ContainerExample(Container):\n      foo: uint64\n      bar: boolean\n  ```\n- **vector**: ordered fixed-length homogeneous collection, with `N` values\n  - notation `Vector[type, N]`, e.g. `Vector[uint64, N]`\n- **list**: ordered variable-length homogeneous collection, limited to `N` values\n  - notation `List[type, N]`, e.g. `List[uint64, N]`\n- **bitvector**: ordered fixed-length collection of `boolean` values, with `N` bits\n  - notation `Bitvector[N]`\n- **bitlist**: ordered variable-length collection of `boolean` values, limited to `N` bits\n  - notation `Bitlist[N]`\n- **union**: union type containing one of the given subtypes\n  - notation `Union[type_0, type_1, ...]`, e.g. `union[null, uint64]`\n\n_Note_: Both `Vector[boolean, N]` and `Bitvector[N]` are valid, yet distinct due to their different serialization requirements. Similarly, both `List[boolean, N]` and `Bitlist[N]` are valid, yet distinct. Generally `Bitvector[N]`/`Bitlist[N]` are preferred because of their serialization efficiencies.\n\n### Variable-size and fixed-size\n\nWe recursively define \"variable-size\" types to be lists, unions, `Bitlist` and all types that contain a variable-size type. All other types are said to be \"fixed-size\".\n\n### Aliases\n\nFor convenience we alias:\n\n- `bit` to `boolean`\n- `byte` to `uint8` (this is a basic type)\n- `BytesN` to `Vector[byte, N]` (this is _not_ a basic type)\n- `null`: `{}`\n\n### Default values\n\nAssuming a helper function `default(type)` which returns the default value for `type`, we can recursively define the default value for all types.\n\n| Type                         | Default Value                           |\n| ---------------------------- | --------------------------------------- |\n| `uintN`                      | `0`                                     |\n| `boolean`                    | `False`                                 |\n| `Container`                  | `[default(type) for type in container]` |\n| `Vector[type, N]`            | `[default(type)] * N`                   |\n| `Bitvector[N]`               | `[False] * N`                           |\n| `List[type, N]`              | `[]`                                    |\n| `Bitlist[N]`                 | `[]`                                    |\n| `Union[type_0, type_1, ...]` | `default(type_0)`                       |\n\n#### `is_zero`\n\nAn SSZ object is called zeroed (and thus, `is_zero(object)` returns true) if it is equal to the default value for that type.\n\n### Illegal types\n\n- Empty vector types (`Vector[type, 0]`, `Bitvector[0]`) are illegal.\n- Containers with no fields are illegal.\n- The `null` type is only legal as the first type in a union subtype (i.e. with type index zero).\n\n## Serialization\n\nWe recursively define the `serialize` function which consumes an object `value` (of the type specified) and returns a bytestring of type `bytes`.\n\n_Note_: In the function definitions below (`serialize`, `hash_tree_root`, `is_variable_size`, etc.) objects implicitly carry their type.\n\n### `uintN`\n\n```python\nassert N in [8, 16, 32, 64, 128, 256]\nreturn value.to_bytes(N // BITS_PER_BYTE, \"little\")\n```\n\n### `boolean`\n\n```python\nassert value in (True, False)\nreturn b\"\\x01\" if value is True else b\"\\x00\"\n```\n\n### `null`\n\n```python\nreturn b\"\"\n```\n\n### `Bitvector[N]`\n\n```python\narray = [0] * ((N + 7) // 8)\nfor i in range(N):\n    array[i // 8] |= value[i] << (i % 8)\nreturn bytes(array)\n```\n\n### `Bitlist[N]`\n\nNote that from the offset coding, the length (in bytes) of the bitlist is known. An additional `1` bit is added to the end, at index `e` where `e` is the length of the bitlist (not the limit), so that the length in bits will also be known.\n\n```python\narray = [0] * ((len(value) // 8) + 1)\nfor i in range(len(value)):\n    array[i // 8] |= value[i] << (i % 8)\narray[len(value) // 8] |= 1 << (len(value) % 8)\nreturn bytes(array)\n```\n\n### Vectors, containers, lists, unions\n\n```python\n# Recursively serialize\nfixed_parts = [serialize(element) if not is_variable_size(element) else None for element in value]\nvariable_parts = [serialize(element) if is_variable_size(element) else b\"\" for element in value]\n\n# Compute and check lengths\nfixed_lengths = [len(part) if part != None else BYTES_PER_LENGTH_OFFSET for part in fixed_parts]\nvariable_lengths = [len(part) for part in variable_parts]\nassert sum(fixed_lengths + variable_lengths) < 2**(BYTES_PER_LENGTH_OFFSET * BITS_PER_BYTE)\n\n# Interleave offsets of variable-size parts with fixed-size parts\nvariable_offsets = [serialize(uint32(sum(fixed_lengths + variable_lengths[:i]))) for i in range(len(value))]\nfixed_parts = [part if part != None else variable_offsets[i] for i, part in enumerate(fixed_parts)]\n\n# Return the concatenation of the fixed-size parts (offsets interleaved) with the variable-size parts\nreturn b\"\".join(fixed_parts + variable_parts)\n```\n\nIf `value` is a union type:\n\nDefine value as an object that has properties `value.value` with the contained value, and `value.type_index` which indexes the type.\n\n```python\nserialized_bytes = serialize(value.value)\nserialized_type_index = value.type_index.to_bytes(BYTES_PER_LENGTH_OFFSET, \"little\")\nreturn serialized_type_index + serialized_bytes\n```\n\n## Deserialization\n\nBecause serialization is an injective function (i.e. two distinct objects of the same type will serialize to different values) any bytestring has at most one object it could deserialize to.\n\nDeserialization can be implemented using a recursive algorithm. The deserialization of basic objects is easy, and from there we can find a simple recursive algorithm for all fixed-size objects. For variable-size objects we have to do one of the following depending on what kind of object it is:\n\n- Vector/list of a variable-size object: The serialized data will start with offsets of all the serialized objects (`BYTES_PER_LENGTH_OFFSET` bytes each).\n  - Using the first offset, we can compute the length of the list (divide by `BYTES_PER_LENGTH_OFFSET`), as it gives us the total number of bytes in the offset data.\n  - The size of each object in the vector/list can be inferred from the difference of two offsets. To get the size of the last object, the total number of bytes has to be known (it is not generally possible to deserialize an SSZ object of unknown length)\n- Containers follow the same principles as vectors, with the difference that there may be fixed-size objects in a container as well. This means the `fixed_parts` data will contain offsets as well as fixed-size objects.\n- In the case of bitlists, the length in bits cannot be uniquely inferred from the number of bytes in the object. Because of this, they have a bit at the end that is always set. This bit has to be used to infer the size of the bitlist in bits.\n\nNote that deserialization requires hardening against invalid inputs. A non-exhaustive list:\n\n- Offsets: out of order, out of range, mismatching minimum element size.\n- Scope: Extra unused bytes, not aligned with element size.\n- More elements than a list limit allows. Part of enforcing consensus.\n\nEfficient algorithms for computing this object can be found in [the implementations](#implementations).\n\n## Merkleization\n\nWe first define helper functions:\n\n- `size_of(B)`, where `B` is a basic type: the length, in bytes, of the serialized form of the basic type.\n- `chunk_count(type)`: calculate the amount of leafs for merkleization of the type.\n  - all basic types: `1`\n  - `Bitlist[N]` and `Bitvector[N]`: `(N + 255) // 256` (dividing by chunk size, rounding up)\n  - `List[B, N]` and `Vector[B, N]`, where `B` is a basic type: `(N * size_of(B) + 31) // 32` (dividing by chunk size, rounding up)\n  - `List[C, N]` and `Vector[C, N]`, where `C` is a composite type: `N`\n  - containers: `len(fields)`\n- `pack(values)`: Given ordered objects of the same basic type:\n  1.  Serialize `values` into bytes.\n  2.  If not aligned to a multiple of `BYTES_PER_CHUNK` bytes, right-pad with zeroes to the next multiple.\n  3.  Partition the bytes into `BYTES_PER_CHUNK`-byte chunks.\n  4.  Return the chunks.\n- `pack_bits(bits)`: Given the bits of bitlist or bitvector, get `bitfield_bytes` by packing them in bytes and aligning to the start. The length-delimiting bit for bitlists is excluded. Then return `pack(bitfield_bytes)`.\n- `next_pow_of_two(i)`: get the next power of 2 of `i`, if not already a power of 2, with 0 mapping to 1. Examples: `0->1, 1->1, 2->2, 3->4, 4->4, 6->8, 9->16`\n- `merkleize(chunks, limit=None)`: Given ordered `BYTES_PER_CHUNK`-byte chunks, merkleize the chunks, and return the root:\n  - The merkleization depends on the effective input, which must be padded/limited:\n    - if no limit: pad the `chunks` with zeroed chunks to `next_pow_of_two(len(chunks))` (virtually for memory efficiency).\n    - if `limit >= len(chunks)`, pad the `chunks` with zeroed chunks to `next_pow_of_two(limit)` (virtually for memory efficiency).\n    - if `limit < len(chunks)`: do not merkleize, input exceeds limit. Raise an error instead.\n  - Then, merkleize the chunks (empty input is padded to 1 zero chunk):\n    - If `1` chunk: the root is the chunk itself.\n    - If `> 1` chunks: merkleize as binary tree.\n- `mix_in_length`: Given a Merkle root `root` and a length `length` (`\"uint256\"` little-endian serialization) return `hash(root + length)`.\n- `mix_in_type`: Given a Merkle root `root` and a type_index `type_index` (`\"uint256\"` little-endian serialization) return `hash(root + type_index)`.\n\nWe now define Merkleization `hash_tree_root(value)` of an object `value` recursively:\n\n- `merkleize(pack(value))` if `value` is a basic object or a vector of basic objects.\n- `merkleize(pack_bits(value), limit=chunk_count(type))` if `value` is a bitvector.\n- `mix_in_length(merkleize(pack(value), limit=chunk_count(type)), len(value))` if `value` is a list of basic objects.\n- `mix_in_length(merkleize(pack_bits(value), limit=chunk_count(type)), len(value))` if `value` is a bitlist.\n- `merkleize([hash_tree_root(element) for element in value])` if `value` is a vector of composite objects or a container.\n- `mix_in_length(merkleize([hash_tree_root(element) for element in value], limit=chunk_count(type)), len(value))` if `value` is a list of composite objects.\n- `mix_in_type(merkleize(value.value), value.type_index)` if `value` is of union type.\n\n## Summaries and expansions\n\nLet `A` be an object derived from another object `B` by replacing some of the (possibly nested) values of `B` by their `hash_tree_root`. We say `A` is a \"summary\" of `B`, and that `B` is an \"expansion\" of `A`. Notice `hash_tree_root(A) == hash_tree_root(B)`.\n\nWe similarly define \"summary types\" and \"expansion types\". For example, [`BeaconBlock`](../specs/phase0/beacon-chain.md#beaconblock) is an expansion type of [`BeaconBlockHeader`](../specs/phase0/beacon-chain.md#beaconblockheader). Notice that objects expand to at most one object of a given expansion type. For example, `BeaconBlockHeader` objects uniquely expand to `BeaconBlock` objects.\n\n## Implementations\n\nSee https://github.com/ethereum/eth2.0-specs/issues/2138 for a list of current known implementations.\n","MerkleProofs":"# Merkle proof formats\n\n**Notice**: This document is a work-in-progress for researchers and implementers\n\n## Helper functions\n\n```python\ndef get_power_of_two_ceil(x: int) -> int:\n    \"\"\"\n    Get the power of 2 for given input, or the closest higher power of 2 if the input is not a power of 2.\n    Commonly used for \"how many nodes do I need for a bottom tree layer fitting x elements?\"\n    Example: 0->1, 1->1, 2->2, 3->4, 4->4, 5->8, 6->8, 7->8, 8->8, 9->16.\n    \"\"\"\n    if x <= 1:\n        return 1\n    elif x == 2:\n        return 2\n    else:\n        return 2 * get_power_of_two_ceil((x + 1) // 2)\n```\n\n```python\ndef get_power_of_two_floor(x: int) -> int:\n    \"\"\"\n    Get the power of 2 for given input, or the closest lower power of 2 if the input is not a power of 2.\n    The zero case is a placeholder and not used for math with generalized indices.\n    Commonly used for \"what power of two makes up the root bit of the generalized index?\"\n    Example: 0->1, 1->1, 2->2, 3->2, 4->4, 5->4, 6->4, 7->4, 8->8, 9->8\n    \"\"\"\n    if x <= 1:\n        return 1\n    if x == 2:\n        return x\n    else:\n        return 2 * get_power_of_two_floor(x // 2)\n```\n\n## Generalized Merkle tree index\n\nIn a binary Merkle tree, we define a \"generalized index\" of a node as `2**depth + index`. Visually, this looks as follows:\n\n```\n    1\n 2     3\n4 5   6 7\n   ...\n```\n\nNote that the generalized index has the convenient property that the two children of node `k` are `2k` and `2k+1`, and also that it equals the position of a node in the linear representation of the Merkle tree that's computed by this function:\n\n```python\ndef merkle_tree(leaves: Sequence[Bytes32]) -> Sequence[Bytes32]:\n    \"\"\"\n    Return an array representing the tree nodes by generalized index:\n    [0, 1, 2, 3, 4, 5, 6, 7], where each layer is a power of 2. The 0 index is ignored. The 1 index is the root.\n    The result will be twice the size as the padded bottom layer for the input leaves.\n    \"\"\"\n    bottom_length = get_power_of_two_ceil(len(leaves))\n    o = [Bytes32()] * bottom_length + list(leaves) + [Bytes32()] * (bottom_length - len(leaves))\n    for i in range(bottom_length - 1, 0, -1):\n        o[i] = hash(o[i * 2] + o[i * 2 + 1])\n    return o\n```\n\nWe define a custom type `GeneralizedIndex` as a Python integer type in this document. It can be represented as a Bitvector/Bitlist object as well.\n\nWe will define Merkle proofs in terms of generalized indices.\n\n## SSZ object to index\n\nWe can describe the hash tree of any SSZ object, rooted in `hash_tree_root(object)`, as a binary Merkle tree whose depth may vary. For example, an object `{x: bytes32, y: List[uint64]}` would look as follows:\n\n```\n     root\n    /    \\\n   x    y_root\n        /    \\\ny_data_root  len(y)\n    / \\\n   /\\ /\\\n  .......\n```\n\nWe can now define a concept of a \"path\", a way of describing a function that takes as input an SSZ object and outputs some specific (possibly deeply nested) member. For example, `foo -> foo.x` is a path, as are `foo -> len(foo.y)` and `foo -> foo.y[5].w`. We'll describe paths as lists, which can have two representations. In \"human-readable form\", they are `[\"x\"]`, `[\"y\", \"__len__\"]` and `[\"y\", 5, \"w\"]` respectively. In \"encoded form\", they are lists of `uint64` values, in these cases (assuming the fields of `foo` in order are `x` then `y`, and `w` is the first field of `y[i]`) `[0]`, `[1, 2**64-1]`, `[1, 5, 0]`. We define `SSZVariableName` as the member variable name string, i.e., a path is presented as a sequence of integers and `SSZVariableName`.\n\n```python\ndef item_length(typ: SSZType) -> int:\n    \"\"\"\n    Return the number of bytes in a basic type, or 32 (a full hash) for compound types.\n    \"\"\"\n    if issubclass(typ, BasicValue):\n        return typ.byte_len\n    else:\n        return 32\n```\n\n```python\ndef get_elem_type(typ: Union[BaseBytes, BaseList, Container],\n                  index_or_variable_name: Union[int, SSZVariableName]) -> SSZType:\n    \"\"\"\n    Return the type of the element of an object of the given type with the given index\n    or member variable name (eg. `7` for `x[7]`, `\"foo\"` for `x.foo`)\n    \"\"\"\n    return typ.get_fields()[index_or_variable_name] if issubclass(typ, Container) else typ.elem_type\n```\n\n```python\ndef chunk_count(typ: SSZType) -> int:\n    \"\"\"\n    Return the number of hashes needed to represent the top-level elements in the given type\n    (eg. `x.foo` or `x[7]` but not `x[7].bar` or `x.foo.baz`). In all cases except lists/vectors\n    of basic types, this is simply the number of top-level elements, as each element gets one\n    hash. For lists/vectors of basic types, it is often fewer because multiple basic elements\n    can be packed into one 32-byte chunk.\n    \"\"\"\n    # typ.length describes the limit for list types, or the length for vector types.\n    if issubclass(typ, BasicValue):\n        return 1\n    elif issubclass(typ, Bits):\n        return (typ.length + 255) // 256\n    elif issubclass(typ, Elements):\n        return (typ.length * item_length(typ.elem_type) + 31) // 32\n    elif issubclass(typ, Container):\n        return len(typ.get_fields())\n    else:\n        raise Exception(f\"Type not supported: {typ}\")\n```\n\n```python\ndef get_item_position(typ: SSZType, index_or_variable_name: Union[int, SSZVariableName]) -> Tuple[int, int, int]:\n    \"\"\"\n    Return three variables:\n        (i) the index of the chunk in which the given element of the item is represented;\n        (ii) the starting byte position within the chunk;\n        (iii) the ending byte position within the chunk.\n    For example: for a 6-item list of uint64 values, index=2 will return (0, 16, 24), index=5 will return (1, 8, 16)\n    \"\"\"\n    if issubclass(typ, Elements):\n        index = int(index_or_variable_name)\n        start = index * item_length(typ.elem_type)\n        return start // 32, start % 32, start % 32 + item_length(typ.elem_type)\n    elif issubclass(typ, Container):\n        variable_name = index_or_variable_name\n        return typ.get_field_names().index(variable_name), 0, item_length(get_elem_type(typ, variable_name))\n    else:\n        raise Exception(\"Only lists/vectors/containers supported\")\n```\n\n```python\ndef get_generalized_index(typ: SSZType, path: Sequence[Union[int, SSZVariableName]]) -> GeneralizedIndex:\n    \"\"\"\n    Converts a path (eg. `[7, \"foo\", 3]` for `x[7].foo[3]`, `[12, \"bar\", \"__len__\"]` for\n    `len(x[12].bar)`) into the generalized index representing its position in the Merkle tree.\n    \"\"\"\n    root = GeneralizedIndex(1)\n    for p in path:\n        assert not issubclass(typ, BasicValue)  # If we descend to a basic type, the path cannot continue further\n        if p == '__len__':\n            typ = uint64\n            assert issubclass(typ, (List, ByteList))\n            root = GeneralizedIndex(root * 2 + 1)\n        else:\n            pos, _, _ = get_item_position(typ, p)\n            base_index = (GeneralizedIndex(2) if issubclass(typ, (List, ByteList)) else GeneralizedIndex(1))\n            root = GeneralizedIndex(root * base_index * get_power_of_two_ceil(chunk_count(typ)) + pos)\n            typ = get_elem_type(typ, p)\n    return root\n```\n\n### Helpers for generalized indices\n\n_Usage note: functions outside this section should manipulate generalized indices using only functions inside this section. This is to make it easier for developers to implement generalized indices with underlying representations other than bigints._\n\n#### `concat_generalized_indices`\n\n```python\ndef concat_generalized_indices(*indices: GeneralizedIndex) -> GeneralizedIndex:\n    \"\"\"\n    Given generalized indices i1 for A -> B, i2 for B -> C .... i_n for Y -> Z, returns\n    the generalized index for A -> Z.\n    \"\"\"\n    o = GeneralizedIndex(1)\n    for i in indices:\n        o = GeneralizedIndex(o * get_power_of_two_floor(i) + (i - get_power_of_two_floor(i)))\n    return o\n```\n\n#### `get_generalized_index_length`\n\n```python\ndef get_generalized_index_length(index: GeneralizedIndex) -> int:\n    \"\"\"\n    Return the length of a path represented by a generalized index.\n    \"\"\"\n    return int(log2(index))\n```\n\n#### `get_generalized_index_bit`\n\n```python\ndef get_generalized_index_bit(index: GeneralizedIndex, position: int) -> bool:\n    \"\"\"\n    Return the given bit of a generalized index.\n    \"\"\"\n    return (index & (1 << position)) > 0\n```\n\n#### `generalized_index_sibling`\n\n```python\ndef generalized_index_sibling(index: GeneralizedIndex) -> GeneralizedIndex:\n    return GeneralizedIndex(index ^ 1)\n```\n\n#### `generalized_index_child`\n\n```python\ndef generalized_index_child(index: GeneralizedIndex, right_side: bool) -> GeneralizedIndex:\n    return GeneralizedIndex(index * 2 + right_side)\n```\n\n#### `generalized_index_parent`\n\n```python\ndef generalized_index_parent(index: GeneralizedIndex) -> GeneralizedIndex:\n    return GeneralizedIndex(index // 2)\n```\n\n## Merkle multiproofs\n\nWe define a Merkle multiproof as a minimal subset of nodes in a Merkle tree needed to fully authenticate that a set of nodes actually are part of a Merkle tree with some specified root, at a particular set of generalized indices. For example, here is the Merkle multiproof for positions 0, 1, 6 in an 8-node Merkle tree (i.e. generalized indices 8, 9, 14):\n\n```\n       .\n   .       .\n .   *   *   .\nx x . . . . x *\n```\n\n. are unused nodes, _ are used nodes, x are the values we are trying to prove. Notice how despite being a multiproof for 3 values, it requires only 3 auxiliary nodes, only one node more than would be required to prove a single value. Normally the efficiency gains are not quite that extreme, but the savings relative to individual Merkle proofs are still significant. As a rule of thumb, a multiproof for k nodes at the same level of an n-node tree has size `k _ (n/k + log(n/k))`.\n\nFirst, we provide a method for computing the generalized indices of the auxiliary tree nodes that a proof of a given set of generalized indices will require:\n\n```python\ndef get_branch_indices(tree_index: GeneralizedIndex) -> Sequence[GeneralizedIndex]:\n    \"\"\"\n    Get the generalized indices of the sister chunks along the path from the chunk with the\n    given tree index to the root.\n    \"\"\"\n    o = [generalized_index_sibling(tree_index)]\n    while o[-1] > 1:\n        o.append(generalized_index_sibling(generalized_index_parent(o[-1])))\n    return o[:-1]\n```\n\n```python\ndef get_path_indices(tree_index: GeneralizedIndex) -> Sequence[GeneralizedIndex]:\n    \"\"\"\n    Get the generalized indices of the chunks along the path from the chunk with the\n    given tree index to the root.\n    \"\"\"\n    o = [tree_index]\n    while o[-1] > 1:\n        o.append(generalized_index_parent(o[-1]))\n    return o[:-1]\n```\n\n```python\ndef get_helper_indices(indices: Sequence[GeneralizedIndex]) -> Sequence[GeneralizedIndex]:\n    \"\"\"\n    Get the generalized indices of all \"extra\" chunks in the tree needed to prove the chunks with the given\n    generalized indices. Note that the decreasing order is chosen deliberately to ensure equivalence to the\n    order of hashes in a regular single-item Merkle proof in the single-item case.\n    \"\"\"\n    all_helper_indices: Set[GeneralizedIndex] = set()\n    all_path_indices: Set[GeneralizedIndex] = set()\n    for index in indices:\n        all_helper_indices = all_helper_indices.union(set(get_branch_indices(index)))\n        all_path_indices = all_path_indices.union(set(get_path_indices(index)))\n\n    return sorted(all_helper_indices.difference(all_path_indices), reverse=True)\n```\n\nNow we provide the Merkle proof verification functions. First, for single item proofs:\n\n```python\ndef calculate_merkle_root(leaf: Bytes32, proof: Sequence[Bytes32], index: GeneralizedIndex) -> Root:\n    assert len(proof) == get_generalized_index_length(index)\n    for i, h in enumerate(proof):\n        if get_generalized_index_bit(index, i):\n            leaf = hash(h + leaf)\n        else:\n            leaf = hash(leaf + h)\n    return leaf\n```\n\n```python\ndef verify_merkle_proof(leaf: Bytes32, proof: Sequence[Bytes32], index: GeneralizedIndex, root: Root) -> bool:\n    return calculate_merkle_root(leaf, proof, index) == root\n```\n\nNow for multi-item proofs:\n\n```python\ndef calculate_multi_merkle_root(leaves: Sequence[Bytes32],\n                                proof: Sequence[Bytes32],\n                                indices: Sequence[GeneralizedIndex]) -> Root:\n    assert len(leaves) == len(indices)\n    helper_indices = get_helper_indices(indices)\n    assert len(proof) == len(helper_indices)\n    objects = {\n        **{index: node for index, node in zip(indices, leaves)},\n        **{index: node for index, node in zip(helper_indices, proof)}\n    }\n    keys = sorted(objects.keys(), reverse=True)\n    pos = 0\n    while pos < len(keys):\n        k = keys[pos]\n        if k in objects and k ^ 1 in objects and k // 2 not in objects:\n            objects[GeneralizedIndex(k // 2)] = hash(\n                objects[GeneralizedIndex((k | 1) ^ 1)] +\n                objects[GeneralizedIndex(k | 1)]\n            )\n            keys.append(GeneralizedIndex(k // 2))\n        pos += 1\n    return objects[GeneralizedIndex(1)]\n```\n\n```python\ndef verify_merkle_multiproof(leaves: Sequence[Bytes32],\n                             proof: Sequence[Bytes32],\n                             indices: Sequence[GeneralizedIndex],\n                             root: Root) -> bool:\n    return calculate_multi_merkle_root(leaves, proof, indices) == root\n```\n\nNote that the single-item proof is a special case of a multi-item proof; a valid single-item proof verifies correctly when put into the multi-item verification function (making the natural trivial changes to input arguments, `index -> [index]` and `leaf -> [leaf]`). Note also that `calculate_merkle_root` and `calculate_multi_merkle_root` can be used independently to compute the new Merkle root of a proof with leaves updated.\n","merkleTOC":"## Table of Contents\n\n- [Helper functions](#helper-functions)\n- [Generalized Merkle tree index](#generalized-merkle-tree-index)\n- [SSZ object to index](#ssz-object-to-index)\n  - [Helpers for generalized indices](#helpers-for-generalized-indices)\n    - [`concat_generalized_indices`](#concat_generalized_indices)\n    - [`get_generalized_index_length`](#get_generalized_index_length)\n    - [`get_generalized_index_bit`](#get_generalized_index_bit)\n    - [`generalized_index_sibling`](#generalized_index_sibling)\n    - [`generalized_index_child`](#generalized_index_child)\n    - [`generalized_index_parent`](#generalized_index_parent)\n- [Merkle multiproofs](#merkle-multiproofs)","specsTOC":"## Table of contents\n\n- [Constants](#constants)\n- [Typing](#typing)\n  - [Basic types](#basic-types)\n  - [Composite types](#composite-types)\n  - [Variable-size and fixed-size](#variable-size-and-fixed-size)\n  - [Aliases](#aliases)\n  - [Default values](#default-values)\n    - [`is_zero`](#is_zero)\n  - [Illegal types](#illegal-types)\n- [Serialization](#serialization)\n  - [`uintN`](#uintn)\n  - [`boolean`](#boolean)\n  - [`null`](#null)\n  - [`Bitvector[N]`](#bitvectorn)\n  - [`Bitlist[N]`](#bitlistn)\n  - [Vectors, containers, lists, unions](#vectors-containers-lists-unions)\n- [Deserialization](#deserialization)\n- [Merkleization](#merkleization)\n- [Summaries and expansions](#summaries-and-expansions)\n- [Implementations](#implementations)\n"},"__N_SSG":true}